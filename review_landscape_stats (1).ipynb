{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées avec succès: 2253 lignes\n",
      "Colonnes disponibles: ['ID', 'NAME', 'STATUS', 'USER', 'WSI_ID', 'CL', 'USER_VALIDATOR']\n"
     ]
    }
   ],
   "source": [
    "def load_data(excel_file, sheet_name=\"Feuil1\"):\n",
    "    \"\"\"\n",
    "    Charge les données du fichier Excel et nettoie les colonnes\n",
    "    \"\"\"\n",
    "    # Charger les données\n",
    "    df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "    \n",
    "    # Nettoyer les noms de colonnes (enlever les espaces)\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    \n",
    "    print(f\"Données chargées avec succès: {len(df)} lignes\")\n",
    "    print(f\"Colonnes disponibles: {list(df.columns)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exécution de la cellule 2\n",
    "excel_file = \"review_landscape_stats.xlsx\"\n",
    "df = load_data(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_statistics(df):\n",
    "    \"\"\"\n",
    "    Calcule les statistiques globales des annotations\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"STATISTIQUES GLOBALES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_annotations = len(df)\n",
    "    total_ok = len(df[df['STATUS'] == 'OK'])\n",
    "    total_nok = total_annotations - total_ok\n",
    "    \n",
    "    print(f\"Total des annotations: {total_annotations}\")\n",
    "    print(f\"Annotations OK: {total_ok} ({(total_ok/total_annotations)*100:.2f}%)\")\n",
    "    print(f\"Annotations NOK: {total_nok} ({(total_nok/total_annotations)*100:.2f}%)\")\n",
    "    \n",
    "    # Statistiques par utilisateur (annotateur)\n",
    "    user_counts = df['USER'].value_counts()\n",
    "    print(\"\\nNombre d'annotations par utilisateur:\")\n",
    "    print(user_counts)\n",
    "    \n",
    "    # Statistiques par validateur\n",
    "    validator_counts = df['USER_VALIDATOR'].value_counts()\n",
    "    print(\"\\nNombre de validations par utilisateur:\")\n",
    "    print(validator_counts)\n",
    "    \n",
    "    return {\n",
    "        'total': total_annotations,\n",
    "        'ok': total_ok,\n",
    "        'nok': total_nok,\n",
    "        'user_counts': user_counts,\n",
    "        'validator_counts': validator_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user4_user9_annotations(df):\n",
    "    \"\"\"\n",
    "    Analyse les annotations faites par User4 et User9\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ANNOTATIONS PAR USER4 ET USER9\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Filtrer les annotations de User4 et User9\n",
    "    user4_user9_df = df[(df['USER'] == 'User4') | (df['USER'] == 'User9')]\n",
    "    \n",
    "    total_user4_user9 = len(user4_user9_df)\n",
    "    ok_user4_user9 = len(user4_user9_df[user4_user9_df['STATUS'] == 'OK'])\n",
    "    nok_user4_user9 = total_user4_user9 - ok_user4_user9\n",
    "    \n",
    "    print(f\"Total des annotations par User4 et User9: {total_user4_user9}\")\n",
    "    print(f\"Annotations OK: {ok_user4_user9} ({(ok_user4_user9/total_user4_user9)*100:.2f}%)\")\n",
    "    print(f\"Annotations NOK: {nok_user4_user9} ({(nok_user4_user9/total_user4_user9)*100:.2f}%)\")\n",
    "    \n",
    "    # Statistiques séparées pour User4\n",
    "    user4_df = df[df['USER'] == 'User4']\n",
    "    total_user4 = len(user4_df)\n",
    "    ok_user4 = len(user4_df[user4_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    print(\"\\nStatistiques pour User4:\")\n",
    "    print(f\"Total des annotations: {total_user4}\")\n",
    "    print(f\"Annotations OK: {ok_user4} ({(ok_user4/total_user4)*100:.2f}%)\")\n",
    "    print(f\"Annotations NOK: {total_user4 - ok_user4} ({((total_user4 - ok_user4)/total_user4)*100:.2f}%)\")\n",
    "    \n",
    "    # Statistiques séparées pour User9\n",
    "    user9_df = df[df['USER'] == 'User9']\n",
    "    total_user9 = len(user9_df)\n",
    "    ok_user9 = len(user9_df[user9_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    print(\"\\nStatistiques pour User9:\")\n",
    "    print(f\"Total des annotations: {total_user9}\")\n",
    "    print(f\"Annotations OK: {ok_user9} ({(ok_user9/total_user9)*100:.2f}%)\")\n",
    "    print(f\"Annotations NOK: {total_user9 - ok_user9} ({((total_user9 - ok_user9)/total_user9)*100:.2f}%)\")\n",
    "    \n",
    "    # Par validateur\n",
    "    validator_counts = user4_user9_df['USER_VALIDATOR'].value_counts()\n",
    "    print(\"\\nValidateurs pour User4 et User9:\")\n",
    "    for validator, count in validator_counts.items():\n",
    "        print(f\"  {validator}: {count} ({(count/total_user4_user9)*100:.2f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'total_user4_user9': total_user4_user9,\n",
    "        'ok_user4_user9': ok_user4_user9,\n",
    "        'nok_user4_user9': nok_user4_user9,\n",
    "        'total_user4': total_user4,\n",
    "        'ok_user4': ok_user4,\n",
    "        'total_user9': total_user9,\n",
    "        'ok_user9': ok_user9,\n",
    "        'validator_counts': validator_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user4_user9_validations(df):\n",
    "    \"\"\"\n",
    "    Analyse les validations faites par User4 et User9\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"VALIDATIONS PAR USER4 ET USER9\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Filtrer les validations de User4 et User9\n",
    "    validated_by_user4_user9_df = df[(df['USER_VALIDATOR'] == 'User4') | (df['USER_VALIDATOR'] == 'User9')]\n",
    "    \n",
    "    total_validated = len(validated_by_user4_user9_df)\n",
    "    ok_validated = len(validated_by_user4_user9_df[validated_by_user4_user9_df['STATUS'] == 'OK'])\n",
    "    nok_validated = total_validated - ok_validated\n",
    "    \n",
    "    print(f\"Total des validations par User4 et User9: {total_validated}\")\n",
    "    print(f\"Validations OK: {ok_validated} ({(ok_validated/total_validated)*100:.2f}%)\")\n",
    "    print(f\"Validations NOK: {nok_validated} ({(nok_validated/total_validated)*100:.2f}%)\")\n",
    "    \n",
    "    # Statistiques séparées pour User4\n",
    "    validated_by_user4_df = df[df['USER_VALIDATOR'] == 'User4']\n",
    "    total_validated_user4 = len(validated_by_user4_df)\n",
    "    ok_validated_user4 = len(validated_by_user4_df[validated_by_user4_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    print(\"\\nStatistiques des validations par User4:\")\n",
    "    print(f\"Total des validations: {total_validated_user4}\")\n",
    "    print(f\"Validations OK: {ok_validated_user4} ({(ok_validated_user4/total_validated_user4)*100:.2f}%)\")\n",
    "    print(f\"Validations NOK: {total_validated_user4 - ok_validated_user4} ({((total_validated_user4 - ok_validated_user4)/total_validated_user4)*100:.2f}%)\")\n",
    "    \n",
    "    # Statistiques séparées pour User9\n",
    "    validated_by_user9_df = df[df['USER_VALIDATOR'] == 'User9']\n",
    "    total_validated_user9 = len(validated_by_user9_df)\n",
    "    ok_validated_user9 = len(validated_by_user9_df[validated_by_user9_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    print(\"\\nStatistiques des validations par User9:\")\n",
    "    print(f\"Total des validations: {total_validated_user9}\")\n",
    "    print(f\"Validations OK: {ok_validated_user9} ({(ok_validated_user9/total_validated_user9)*100:.2f}%)\")\n",
    "    print(f\"Validations NOK: {total_validated_user9 - ok_validated_user9} ({((total_validated_user9 - ok_validated_user9)/total_validated_user9)*100:.2f}%)\")\n",
    "    \n",
    "    # Par annotateur\n",
    "    annotator_counts = validated_by_user4_user9_df['USER'].value_counts()\n",
    "    print(\"\\nAnnotateurs validés par User4 et User9:\")\n",
    "    for annotator, count in annotator_counts.items():\n",
    "        print(f\"  {annotator}: {count} ({(count/total_validated)*100:.2f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'total_validated': total_validated,\n",
    "        'ok_validated': ok_validated,\n",
    "        'nok_validated': nok_validated,\n",
    "        'total_validated_user4': total_validated_user4,\n",
    "        'ok_validated_user4': ok_validated_user4,\n",
    "        'total_validated_user9': total_validated_user9,\n",
    "        'ok_validated_user9': ok_validated_user9,\n",
    "        'annotator_counts': annotator_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_others(df):\n",
    "    \"\"\"\n",
    "    Compare les statistiques de User4 et User9 avec les autres utilisateurs\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"COMPARAISON AVEC LES AUTRES UTILISATEURS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Pour les annotations\n",
    "    user4_user9_df = df[(df['USER'] == 'User4') | (df['USER'] == 'User9')]\n",
    "    others_df = df[(df['USER'] != 'User4') & (df['USER'] != 'User9')]\n",
    "    \n",
    "    total_user4_user9 = len(user4_user9_df)\n",
    "    ok_user4_user9 = len(user4_user9_df[user4_user9_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    total_others = len(others_df)\n",
    "    ok_others = len(others_df[others_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    print(\"Taux de validation pour les annotations:\")\n",
    "    print(f\"  User4 et User9: {(ok_user4_user9/total_user4_user9)*100:.2f}%\")\n",
    "    print(f\"  Autres utilisateurs: {(ok_others/total_others)*100:.2f}%\")\n",
    "    print(f\"  Différence: {(ok_user4_user9/total_user4_user9)*100 - (ok_others/total_others)*100:.2f}%\")\n",
    "    \n",
    "    # Pour les validations\n",
    "    validated_by_user4_user9_df = df[(df['USER_VALIDATOR'] == 'User4') | (df['USER_VALIDATOR'] == 'User9')]\n",
    "    validated_by_others_df = df[(df['USER_VALIDATOR'] != 'User4') & (df['USER_VALIDATOR'] != 'User9')]\n",
    "    \n",
    "    total_validated_by_user4_user9 = len(validated_by_user4_user9_df)\n",
    "    ok_validated_by_user4_user9 = len(validated_by_user4_user9_df[validated_by_user4_user9_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    total_validated_by_others = len(validated_by_others_df)\n",
    "    ok_validated_by_others = len(validated_by_others_df[validated_by_others_df['STATUS'] == 'OK'])\n",
    "    \n",
    "    print(\"\\nTaux de validation pour les validations:\")\n",
    "    print(f\"  User4 et User9: {(ok_validated_by_user4_user9/total_validated_by_user4_user9)*100:.2f}%\")\n",
    "    print(f\"  Autres utilisateurs: {(ok_validated_by_others/total_validated_by_others)*100:.2f}%\")\n",
    "    print(f\"  Différence: {(ok_validated_by_user4_user9/total_validated_by_user4_user9)*100 - (ok_validated_by_others/total_validated_by_others)*100:.2f}%\")\n",
    "    \n",
    "    # Test statistique pour déterminer si les différences sont significatives\n",
    "    # Test pour les annotations\n",
    "    user4_user9_annot = user4_user9_df['STATUS'].map({'OK': 1, 'NOK': 0}).values\n",
    "    others_annot = others_df['STATUS'].map({'OK': 1, 'NOK': 0}).values\n",
    "    \n",
    "    t_stat_annot, p_value_annot = stats.ttest_ind(user4_user9_annot, others_annot, equal_var=False)\n",
    "    \n",
    "    # Test pour les validations\n",
    "    user4_user9_valid = validated_by_user4_user9_df['STATUS'].map({'OK': 1, 'NOK': 0}).values\n",
    "    others_valid = validated_by_others_df['STATUS'].map({'OK': 1, 'NOK': 0}).values\n",
    "    \n",
    "    t_stat_valid, p_value_valid = stats.ttest_ind(user4_user9_valid, others_valid, equal_var=False)\n",
    "    \n",
    "    print(\"\\nTests statistiques:\")\n",
    "    print(f\"  p-value pour les annotations: {p_value_annot:.5f}\")\n",
    "    if p_value_annot < 0.05:\n",
    "        print(\"  La différence est statistiquement significative (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"  La différence n'est pas statistiquement significative (p >= 0.05)\")\n",
    "    \n",
    "    print(f\"\\n  p-value pour les validations: {p_value_valid:.5f}\")\n",
    "    if p_value_valid < 0.05:\n",
    "        print(\"  La différence est statistiquement significative (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"  La différence n'est pas statistiquement significative (p >= 0.05)\")\n",
    "    \n",
    "    return {\n",
    "        'user4_user9_ok_rate': (ok_user4_user9/total_user4_user9)*100,\n",
    "        'others_ok_rate': (ok_others/total_others)*100,\n",
    "        'validated_by_user4_user9_ok_rate': (ok_validated_by_user4_user9/total_validated_by_user4_user9)*100,\n",
    "        'validated_by_others_ok_rate': (ok_validated_by_others/total_validated_by_others)*100,\n",
    "        'p_value_annot': p_value_annot,\n",
    "        'p_value_valid': p_value_valid\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_classes(df):\n",
    "    \"\"\"\n",
    "    Analyse les classes annotées par User4 et User9\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ANALYSE DES CLASSES ANNOTÉES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Classes annotées par User4\n",
    "    user4_df = df[df['USER'] == 'User4']\n",
    "    user4_classes = user4_df['CL'].value_counts()\n",
    "    \n",
    "    print(\"Top 5 des classes annotées par User4:\")\n",
    "    for cl, count in user4_classes.head(5).items():\n",
    "        print(f\"  {cl}: {count} ({(count/len(user4_df))*100:.2f}%)\")\n",
    "    \n",
    "    # Classes annotées par User9\n",
    "    user9_df = df[df['USER'] == 'User9']\n",
    "    user9_classes = user9_df['CL'].value_counts()\n",
    "    \n",
    "    print(\"\\nTop 5 des classes annotées par User9:\")\n",
    "    for cl, count in user9_classes.head(5).items():\n",
    "        print(f\"  {cl}: {count} ({(count/len(user9_df))*100:.2f}%)\")\n",
    "    \n",
    "    # Classes communes\n",
    "    common_classes = set(user4_classes.index) & set(user9_classes.index)\n",
    "    print(f\"\\nNombre de classes communes entre User4 et User9: {len(common_classes)}\")\n",
    "    \n",
    "    # Top 5 des classes communes\n",
    "    if common_classes:\n",
    "        print(\"Top classes communes:\")\n",
    "        common_class_counts = {}\n",
    "        for cl in common_classes:\n",
    "            common_class_counts[cl] = user4_classes.get(cl, 0) + user9_classes.get(cl, 0)\n",
    "        \n",
    "        top_common = sorted(common_class_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        for cl, count in top_common:\n",
    "            print(f\"  {cl}: {count} (User4: {user4_classes.get(cl, 0)}, User9: {user9_classes.get(cl, 0)})\")\n",
    "    \n",
    "    return {\n",
    "        'user4_classes': user4_classes,\n",
    "        'user9_classes': user9_classes,\n",
    "        'common_classes': common_classes\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_visualizations(results):\n",
    "    \"\"\"\n",
    "    Crée des visualisations de base pour les statistiques d'annotations\n",
    "    \"\"\"\n",
    "    # Configuration générale\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    # 1. Taux de validation comme annotateurs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    users = ['User4', 'User9', 'User4+User9', 'Autres']\n",
    "    rates = [\n",
    "        results['annotations']['ok_user4'] / results['annotations']['total_user4'] * 100,\n",
    "        results['annotations']['ok_user9'] / results['annotations']['total_user9'] * 100,\n",
    "        results['annotations']['ok_user4_user9'] / results['annotations']['total_user4_user9'] * 100,\n",
    "        results['comparison']['others_ok_rate']\n",
    "    ]\n",
    "    \n",
    "    bars = plt.bar(users, rates, color=['blue', 'green', 'orange', 'gray'])\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{height:.2f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Taux de validation des annotations')\n",
    "    plt.ylabel('Taux de validation (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig('taux_validation_annotations.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Taux de validation comme validateurs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    rates_validators = [\n",
    "        results['validations']['ok_validated_user4'] / results['validations']['total_validated_user4'] * 100,\n",
    "        results['validations']['ok_validated_user9'] / results['validations']['total_validated_user9'] * 100,\n",
    "        results['validations']['ok_validated'] / results['validations']['total_validated'] * 100,\n",
    "        results['comparison']['validated_by_others_ok_rate']\n",
    "    ]\n",
    "    \n",
    "    bars = plt.bar(users, rates_validators, color=['blue', 'green', 'orange', 'gray'])\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{height:.2f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Taux de validation en tant que validateurs')\n",
    "    plt.ylabel('Taux de validation (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig('taux_validation_validateurs.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nLes visualisations de base ont été enregistrées dans les fichiers suivants:\")\n",
    "    print(\"- taux_validation_annotations.png\")\n",
    "    print(\"- taux_validation_validateurs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_visualizations(df, results):\n",
    "    \"\"\"\n",
    "    Crée des visualisations avancées pour l'analyse comparative\n",
    "    \"\"\"\n",
    "    # Configuration de seaborn\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # 1. Comparaison des taux de validation par utilisateur\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Créer un DataFrame avec les statistiques par utilisateur\n",
    "    user_stats = []\n",
    "    for user in df['USER'].unique():\n",
    "        user_df = df[df['USER'] == user]\n",
    "        total = len(user_df)\n",
    "        if total < 10:  # Ignorer les utilisateurs avec moins de 10 annotations\n",
    "            continue\n",
    "        ok = len(user_df[user_df['STATUS'] == 'OK'])\n",
    "        user_stats.append({\n",
    "            'USER': user,\n",
    "            'Total': total,\n",
    "            'OK': ok,\n",
    "            'Taux_OK': (ok/total)*100\n",
    "        })\n",
    "    \n",
    "    user_stats_df = pd.DataFrame(user_stats)\n",
    "    user_stats_df = user_stats_df.sort_values('Taux_OK', ascending=False)\n",
    "    \n",
    "    # Mettre en évidence User4 et User9\n",
    "    colors = ['blue' if user == 'User4' else 'green' if user == 'User9' else 'gray' \n",
    "              for user in user_stats_df['USER']]\n",
    "    \n",
    "    # Créer le graphique\n",
    "    bars = plt.bar(user_stats_df['USER'], user_stats_df['Taux_OK'], color=colors)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.title('Taux de validation par utilisateur (annotateur)', fontsize=14)\n",
    "    plt.ylabel('Taux de validation (%)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('taux_validation_par_user.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Comparaison des taux de validation par validateur\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Créer un DataFrame avec les statistiques par validateur\n",
    "    validator_stats = []\n",
    "    for validator in df['USER_VALIDATOR'].unique():\n",
    "        validator_df = df[df['USER_VALIDATOR'] == validator]\n",
    "        total = len(validator_df)\n",
    "        if total < 10:  # Ignorer les validateurs avec moins de 10 validations\n",
    "            continue\n",
    "        ok = len(validator_df[validator_df['STATUS'] == 'OK'])\n",
    "        validator_stats.append({\n",
    "            'USER_VALIDATOR': validator,\n",
    "            'Total': total,\n",
    "            'OK': ok,\n",
    "            'Taux_OK': (ok/total)*100\n",
    "        })\n",
    "    \n",
    "    validator_stats_df = pd.DataFrame(validator_stats)\n",
    "    validator_stats_df = validator_stats_df.sort_values('Taux_OK', ascending=False)\n",
    "    \n",
    "    # Mettre en évidence User4 et User9\n",
    "    colors = ['blue' if validator == 'User4' else 'green' if validator == 'User9' else 'gray' \n",
    "              for validator in validator_stats_df['USER_VALIDATOR']]\n",
    "    \n",
    "    # Créer le graphique\n",
    "    bars = plt.bar(validator_stats_df['USER_VALIDATOR'], validator_stats_df['Taux_OK'], color=colors)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.title('Taux de validation par validateur', fontsize=14)\n",
    "    plt.ylabel('Taux de validation (%)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('taux_validation_par_validateur.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Matrice de confusion pour User4 comme validateur\n",
    "    user4_validator_df = df[df['USER_VALIDATOR'] == 'User4']\n",
    "    if not user4_validator_df.empty:\n",
    "        # Créer une table croisée des statuts par utilisateur\n",
    "        user4_validator_crosstab = pd.crosstab(user4_validator_df['USER'], user4_validator_df['STATUS'])\n",
    "        \n",
    "        # Ajouter les totaux et les taux\n",
    "        if 'OK' in user4_validator_crosstab.columns and 'NOK' in user4_validator_crosstab.columns:\n",
    "            user4_validator_crosstab['Total'] = user4_validator_crosstab['OK'] + user4_validator_crosstab['NOK']\n",
    "            user4_validator_crosstab['Taux_OK'] = user4_validator_crosstab['OK'] / user4_validator_crosstab['Total'] * 100\n",
    "            \n",
    "            # Filtrer les utilisateurs avec au moins 5 annotations\n",
    "            user4_validator_crosstab = user4_validator_crosstab[user4_validator_crosstab['Total'] >= 5]\n",
    "            \n",
    "            # Trier par taux de validation\n",
    "            user4_validator_crosstab = user4_validator_crosstab.sort_values('Taux_OK', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Heatmap des valeurs absolues\n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.heatmap(user4_validator_crosstab[['OK', 'NOK']], annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('User4 comme validateur\\n(nombre absolu)', fontsize=12)\n",
    "            \n",
    "            # Heatmap des pourcentages\n",
    "            plt.subplot(1, 2, 2)\n",
    "            percentage_data = user4_validator_crosstab[['OK', 'NOK']].div(user4_validator_crosstab['Total'], axis=0) * 100\n",
    "            sns.heatmap(percentage_data, annot=True, fmt='.1f', cmap='Blues')\n",
    "            plt.title('User4 comme validateur\\n(pourcentage)', fontsize=12)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('confusion_matrix_user4.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # 4. Matrice de confusion pour User9 comme validateur\n",
    "    user9_validator_df = df[df['USER_VALIDATOR'] == 'User9']\n",
    "    if not user9_validator_df.empty:\n",
    "        # Créer une table croisée des statuts par utilisateur\n",
    "        user9_validator_crosstab = pd.crosstab(user9_validator_df['USER'], user9_validator_df['STATUS'])\n",
    "        \n",
    "        # Ajouter les totaux et les taux\n",
    "        if 'OK' in user9_validator_crosstab.columns and 'NOK' in user9_validator_crosstab.columns:\n",
    "            user9_validator_crosstab['Total'] = user9_validator_crosstab['OK'] + user9_validator_crosstab['NOK']\n",
    "            user9_validator_crosstab['Taux_OK'] = user9_validator_crosstab['OK'] / user9_validator_crosstab['Total'] * 100\n",
    "            \n",
    "            # Filtrer les utilisateurs avec au moins 5 annotations\n",
    "            user9_validator_crosstab = user9_validator_crosstab[user9_validator_crosstab['Total'] >= 5]\n",
    "            \n",
    "            # Trier par taux de validation\n",
    "            user9_validator_crosstab = user9_validator_crosstab.sort_values('Taux_OK', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Heatmap des valeurs absolues\n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.heatmap(user9_validator_crosstab[['OK', 'NOK']], annot=True, fmt='d', cmap='Greens')\n",
    "            plt.title('User9 comme validateur\\n(nombre absolu)', fontsize=12)\n",
    "            \n",
    "            # Heatmap des pourcentages\n",
    "            plt.subplot(1, 2, 2)\n",
    "            percentage_data = user9_validator_crosstab[['OK', 'NOK']].div(user9_validator_crosstab['Total'], axis=0) * 100\n",
    "            sns.heatmap(percentage_data, annot=True, fmt='.1f', cmap='Greens')\n",
    "            plt.title('User9 comme validateur\\n(pourcentage)', fontsize=12)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('confusion_matrix_user9.png')\n",
    "            plt.close()\n",
    "    \n",
    "    print(\"\\nLes visualisations avancées ont été enregistrées dans les fichiers suivants:\")\n",
    "    print(\"- taux_validation_par_user.png\")\n",
    "    print(\"- taux_validation_par_validateur.png\")\n",
    "    print(\"- confusion_matrix_user4.png\")\n",
    "    print(\"- confusion_matrix_user9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale qui exécute l'analyse complète\n",
    "    \"\"\"\n",
    "    print(\"Analyse des annotations des utilisateurs 4 et 9\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Charger les données\n",
    "    excel_file = \"./review_landscape_stats.xlsx\"\n",
    "    df = load_data(excel_file)\n",
    "    \n",
    "    # Exécuter les analyses\n",
    "    global_stats = global_statistics(df)\n",
    "    annotations_stats = analyze_user4_user9_annotations(df)\n",
    "    validations_stats = analyze_user4_user9_validations(df)\n",
    "    comparison_stats = compare_with_others(df)\n",
    "    classes_stats = analyze_classes(df)\n",
    "    \n",
    "    # Regrouper les résultats\n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NOUVELLES CELLULES À AJOUTER AU NOTEBOOK EXISTANT\n",
    "# ============================================================================\n",
    "\n",
    "# CELLULE 1: Analyse globale des types d'annotations\n",
    "def analyze_annotation_types_global(df):\n",
    "    \"\"\"\n",
    "    Analyse globale des types d'annotations\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ANALYSE GLOBALE DES TYPES D'ANNOTATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Statistiques générales par type\n",
    "    type_counts = df['CL'].value_counts()\n",
    "    type_stats = {}\n",
    "    \n",
    "    print(f\"Nombre total de types d'annotations: {len(type_counts)}\")\n",
    "    print(f\"Total des annotations: {len(df)}\")\n",
    "    \n",
    "    print(\"\\nTop 10 des types les plus fréquents:\")\n",
    "    for i, (annotation_type, count) in enumerate(type_counts.head(10).items(), 1):\n",
    "        type_df = df[df['CL'] == annotation_type]\n",
    "        ok_count = len(type_df[type_df['STATUS'] == 'OK'])\n",
    "        ok_rate = (ok_count / count) * 100\n",
    "        \n",
    "        type_stats[annotation_type] = {\n",
    "            'total': count,\n",
    "            'ok': ok_count,\n",
    "            'nok': count - ok_count,\n",
    "            'ok_rate': ok_rate\n",
    "        }\n",
    "        \n",
    "        print(f\"  {i:2d}. {annotation_type}: {count} annotations ({ok_rate:.2f}% OK)\")\n",
    "    \n",
    "    return type_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 2: Analyse des types d'annotations par utilisateur\n",
    "def analyze_annotation_types_by_user(df, target_users=['User4', 'User9']):\n",
    "    \"\"\"\n",
    "    Analyse des types d'annotations par utilisateur spécifique\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ANALYSE DES TYPES D'ANNOTATIONS PAR {' ET '.join(target_users)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for user in target_users:\n",
    "        print(f\"\\n--- Analyse pour {user} ---\")\n",
    "        user_df = df[df['USER'] == user]\n",
    "        \n",
    "        if len(user_df) == 0:\n",
    "            print(f\"Aucune annotation trouvée pour {user}\")\n",
    "            continue\n",
    "            \n",
    "        user_type_counts = user_df['CL'].value_counts()\n",
    "        user_stats = {}\n",
    "        \n",
    "        print(f\"Nombre de types annotés par {user}: {len(user_type_counts)}\")\n",
    "        print(f\"Total des annotations par {user}: {len(user_df)}\")\n",
    "        \n",
    "        print(f\"\\nTop 10 des types annotés par {user}:\")\n",
    "        for i, (annotation_type, count) in enumerate(user_type_counts.head(10).items(), 1):\n",
    "            type_df = user_df[user_df['CL'] == annotation_type]\n",
    "            ok_count = len(type_df[type_df['STATUS'] == 'OK'])\n",
    "            ok_rate = (ok_count / count) * 100\n",
    "            \n",
    "            user_stats[annotation_type] = {\n",
    "                'total': count,\n",
    "                'ok': ok_count,\n",
    "                'nok': count - ok_count,\n",
    "                'ok_rate': ok_rate\n",
    "            }\n",
    "            \n",
    "            print(f\"  {i:2d}. {annotation_type}: {count} annotations ({ok_rate:.2f}% OK)\")\n",
    "        \n",
    "        results[user] = user_stats\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 3: Taux de validation par type d'annotation\n",
    "def analyze_annotation_types_validation_rates(df):\n",
    "    \"\"\"\n",
    "    Analyse des taux de validation par type d'annotation\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TAUX DE VALIDATION PAR TYPE D'ANNOTATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    type_validation_stats = {}\n",
    "    type_counts = df['CL'].value_counts()\n",
    "    \n",
    "    # Analyser seulement les types avec au moins 10 annotations\n",
    "    significant_types = type_counts[type_counts >= 10].index\n",
    "    \n",
    "    validation_data = []\n",
    "    \n",
    "    for annotation_type in significant_types:\n",
    "        type_df = df[df['CL'] == annotation_type]\n",
    "        total = len(type_df)\n",
    "        ok = len(type_df[type_df['STATUS'] == 'OK'])\n",
    "        ok_rate = (ok / total) * 100\n",
    "        \n",
    "        type_validation_stats[annotation_type] = {\n",
    "            'total': total,\n",
    "            'ok': ok,\n",
    "            'nok': total - ok,\n",
    "            'ok_rate': ok_rate\n",
    "        }\n",
    "        \n",
    "        validation_data.append({\n",
    "            'type': annotation_type,\n",
    "            'total': total,\n",
    "            'ok_rate': ok_rate\n",
    "        })\n",
    "    \n",
    "    # Trier par taux de validation\n",
    "    validation_data.sort(key=lambda x: x['ok_rate'], reverse=True)\n",
    "    \n",
    "    print(\"Types d'annotations avec les MEILLEURS taux de validation (≥10 annotations):\")\n",
    "    for i, data in enumerate(validation_data[:10], 1):\n",
    "        print(f\"  {i:2d}. {data['type']}: {data['ok_rate']:.2f}% OK ({data['total']} total)\")\n",
    "    \n",
    "    print(\"\\nTypes d'annotations avec les PLUS FAIBLES taux de validation (≥10 annotations):\")\n",
    "    for i, data in enumerate(validation_data[-10:], 1):\n",
    "        print(f\"  {i:2d}. {data['type']}: {data['ok_rate']:.2f}% OK ({data['total']} total)\")\n",
    "    \n",
    "    return type_validation_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 4: Performance des utilisateurs par type d'annotation\n",
    "def analyze_user_performance_by_annotation_type(df, target_users=['User4', 'User9']):\n",
    "    \"\"\"\n",
    "    Analyse des performances des utilisateurs spécifiques par type d'annotation\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"PERFORMANCE DE {' ET '.join(target_users)} PAR TYPE D'ANNOTATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for user in target_users:\n",
    "        print(f\"\\n--- Performance de {user} par type ---\")\n",
    "        user_df = df[df['USER'] == user]\n",
    "        \n",
    "        if len(user_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        user_type_performance = {}\n",
    "        user_type_counts = user_df['CL'].value_counts()\n",
    "        \n",
    "        # Analyser les types avec au moins 5 annotations par cet utilisateur\n",
    "        significant_types = user_type_counts[user_type_counts >= 5].index\n",
    "        \n",
    "        performance_data = []\n",
    "        \n",
    "        for annotation_type in significant_types:\n",
    "            type_df = user_df[user_df['CL'] == annotation_type]\n",
    "            total = len(type_df)\n",
    "            ok = len(type_df[type_df['STATUS'] == 'OK'])\n",
    "            ok_rate = (ok / total) * 100\n",
    "            \n",
    "            user_type_performance[annotation_type] = {\n",
    "                'total': total,\n",
    "                'ok': ok,\n",
    "                'ok_rate': ok_rate\n",
    "            }\n",
    "            \n",
    "            performance_data.append({\n",
    "                'type': annotation_type,\n",
    "                'total': total,\n",
    "                'ok_rate': ok_rate\n",
    "            })\n",
    "        \n",
    "        # Trier par taux de validation\n",
    "        performance_data.sort(key=lambda x: x['ok_rate'], reverse=True)\n",
    "        \n",
    "        print(f\"Meilleure performance de {user} (≥5 annotations par type):\")\n",
    "        for i, data in enumerate(performance_data[:5], 1):\n",
    "            print(f\"  {i}. {data['type']}: {data['ok_rate']:.2f}% OK ({data['total']} total)\")\n",
    "        \n",
    "        if len(performance_data) > 5:\n",
    "            print(f\"\\nPlus faible performance de {user}:\")\n",
    "            for i, data in enumerate(performance_data[-5:], 1):\n",
    "                print(f\"  {i}. {data['type']}: {data['ok_rate']:.2f}% OK ({data['total']} total)\")\n",
    "        \n",
    "        results[user] = user_type_performance\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 5: Comparaison entre User4 et User9 par type\n",
    "def compare_annotation_types_between_users(df, user1='User4', user2='User9'):\n",
    "    \"\"\"\n",
    "    Compare les performances entre deux utilisateurs pour les mêmes types d'annotations\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"COMPARAISON {user1} vs {user2} PAR TYPE D'ANNOTATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    user1_df = df[df['USER'] == user1]\n",
    "    user2_df = df[df['USER'] == user2]\n",
    "    \n",
    "    # Trouver les types communs avec au moins 3 annotations par utilisateur\n",
    "    user1_types = set(user1_df['CL'].value_counts()[user1_df['CL'].value_counts() >= 3].index)\n",
    "    user2_types = set(user2_df['CL'].value_counts()[user2_df['CL'].value_counts() >= 3].index)\n",
    "    common_types = user1_types & user2_types\n",
    "    \n",
    "    print(f\"Types d'annotations communs entre {user1} et {user2} (≥3 par utilisateur): {len(common_types)}\")\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for annotation_type in common_types:\n",
    "        user1_type_df = user1_df[user1_df['CL'] == annotation_type]\n",
    "        user2_type_df = user2_df[user2_df['CL'] == annotation_type]\n",
    "        \n",
    "        user1_total = len(user1_type_df)\n",
    "        user1_ok = len(user1_type_df[user1_type_df['STATUS'] == 'OK'])\n",
    "        user1_ok_rate = (user1_ok / user1_total) * 100\n",
    "        \n",
    "        user2_total = len(user2_type_df)\n",
    "        user2_ok = len(user2_type_df[user2_type_df['STATUS'] == 'OK'])\n",
    "        user2_ok_rate = (user2_ok / user2_total) * 100\n",
    "        \n",
    "        difference = user1_ok_rate - user2_ok_rate\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'type': annotation_type,\n",
    "            'user1_rate': user1_ok_rate,\n",
    "            'user2_rate': user2_ok_rate,\n",
    "            'difference': difference,\n",
    "            'user1_total': user1_total,\n",
    "            'user2_total': user2_total\n",
    "        })\n",
    "    \n",
    "    # Trier par différence absolue\n",
    "    comparison_data.sort(key=lambda x: abs(x['difference']), reverse=True)\n",
    "    \n",
    "    print(f\"\\nPlus grandes différences de performance entre {user1} et {user2}:\")\n",
    "    for i, data in enumerate(comparison_data[:10], 1):\n",
    "        better_user = user1 if data['difference'] > 0 else user2\n",
    "        print(f\"  {i:2d}. {data['type']}:\")\n",
    "        print(f\"      {user1}: {data['user1_rate']:.1f}% OK ({data['user1_total']} total)\")\n",
    "        print(f\"      {user2}: {data['user2_rate']:.1f}% OK ({data['user2_total']} total)\")\n",
    "        print(f\"      Différence: {abs(data['difference']):.1f}% (avantage {better_user})\")\n",
    "    \n",
    "    return comparison_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 6: Analyse des validations par type\n",
    "def analyze_annotation_types_by_validator(df, target_validators=['User4', 'User9']):\n",
    "    \"\"\"\n",
    "    Analyse des types d'annotations validées par des validateurs spécifiques\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"VALIDATIONS PAR TYPE - VALIDATEURS {' ET '.join(target_validators)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for validator in target_validators:\n",
    "        print(f\"\\n--- Validations par {validator} ---\")\n",
    "        validator_df = df[df['USER_VALIDATOR'] == validator]\n",
    "        \n",
    "        if len(validator_df) == 0:\n",
    "            print(f\"Aucune validation trouvée pour {validator}\")\n",
    "            continue\n",
    "            \n",
    "        validator_type_counts = validator_df['CL'].value_counts()\n",
    "        validator_stats = {}\n",
    "        \n",
    "        print(f\"Nombre de types validés par {validator}: {len(validator_type_counts)}\")\n",
    "        print(f\"Total des validations par {validator}: {len(validator_df)}\")\n",
    "        \n",
    "        print(f\"\\nTop 10 des types validés par {validator}:\")\n",
    "        for i, (annotation_type, count) in enumerate(validator_type_counts.head(10).items(), 1):\n",
    "            type_df = validator_df[validator_df['CL'] == annotation_type]\n",
    "            ok_count = len(type_df[type_df['STATUS'] == 'OK'])\n",
    "            ok_rate = (ok_count / count) * 100\n",
    "            \n",
    "            validator_stats[annotation_type] = {\n",
    "                'total': count,\n",
    "                'ok': ok_count,\n",
    "                'nok': count - ok_count,\n",
    "                'ok_rate': ok_rate\n",
    "            }\n",
    "            \n",
    "            print(f\"  {i:2d}. {annotation_type}: {count} validations ({ok_rate:.2f}% OK)\")\n",
    "        \n",
    "        results[validator] = validator_stats\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 7: Visualisations par type d'annotation\n",
    "def create_annotation_type_visualizations(df, results):\n",
    "    \"\"\"\n",
    "    Créer des visualisations pour l'analyse par type d'annotation\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CRÉATION DES VISUALISATIONS PAR TYPE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Configuration\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    # 1. Taux de validation par type d'annotation (top 15)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    type_counts = df['CL'].value_counts()\n",
    "    significant_types = type_counts[type_counts >= 10].index[:15]  # Top 15 avec au moins 10 annotations\n",
    "    \n",
    "    rates_data = []\n",
    "    type_names = []\n",
    "    \n",
    "    for annotation_type in significant_types:\n",
    "        type_df = df[df['CL'] == annotation_type]\n",
    "        ok_rate = (len(type_df[type_df['STATUS'] == 'OK']) / len(type_df)) * 100\n",
    "        rates_data.append(ok_rate)\n",
    "        # Tronquer les noms longs pour l'affichage\n",
    "        display_name = annotation_type if len(annotation_type) <= 30 else annotation_type[:27] + \"...\"\n",
    "        type_names.append(display_name)\n",
    "    \n",
    "    # Trier par taux de validation\n",
    "    sorted_data = sorted(zip(rates_data, type_names), reverse=True)\n",
    "    rates_data, type_names = zip(*sorted_data)\n",
    "    \n",
    "    bars = plt.barh(range(len(type_names)), rates_data, color='skyblue')\n",
    "    \n",
    "    # Ajouter les valeurs\n",
    "    for i, (bar, rate) in enumerate(zip(bars, rates_data)):\n",
    "        plt.text(rate + 1, i, f'{rate:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    plt.yticks(range(len(type_names)), type_names, fontsize=10)\n",
    "    plt.xlabel('Taux de validation (%)', fontsize=12)\n",
    "    plt.title('Taux de validation par type d\\'annotation (Top 15)', fontsize=14)\n",
    "    plt.xlim(0, 105)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('taux_validation_par_type.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Performance User4 vs User9 par type\n",
    "    user4_df = df[df['USER'] == 'User4']\n",
    "    user9_df = df[df['USER'] == 'User9']\n",
    "    \n",
    "    # Trouver types communs avec au moins 5 annotations\n",
    "    user4_types = set(user4_df['CL'].value_counts()[user4_df['CL'].value_counts() >= 5].index)\n",
    "    user9_types = set(user9_df['CL'].value_counts()[user9_df['CL'].value_counts() >= 5].index)\n",
    "    common_types = list(user4_types & user9_types)[:10]  # Top 10\n",
    "    \n",
    "    if common_types:\n",
    "        user4_rates = []\n",
    "        user9_rates = []\n",
    "        \n",
    "        for annotation_type in common_types:\n",
    "            user4_type_df = user4_df[user4_df['CL'] == annotation_type]\n",
    "            user4_rate = (len(user4_type_df[user4_type_df['STATUS'] == 'OK']) / len(user4_type_df)) * 100\n",
    "            user4_rates.append(user4_rate)\n",
    "            \n",
    "            user9_type_df = user9_df[user9_df['CL'] == annotation_type]\n",
    "            user9_rate = (len(user9_type_df[user9_type_df['STATUS'] == 'OK']) / len(user9_type_df)) * 100\n",
    "            user9_rates.append(user9_rate)\n",
    "        \n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        x = np.arange(len(common_types))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, user4_rates, width, label='User4', color='blue', alpha=0.7)\n",
    "        plt.bar(x + width/2, user9_rates, width, label='User9', color='green', alpha=0.7)\n",
    "        \n",
    "        # Tronquer les noms pour l'affichage\n",
    "        display_names = [name[:20] + \"...\" if len(name) > 20 else name for name in common_types]\n",
    "        plt.xticks(x, display_names, rotation=45, ha='right', fontsize=10)\n",
    "        plt.ylabel('Taux de validation (%)', fontsize=12)\n",
    "        plt.title('Comparaison User4 vs User9 par type d\\'annotation', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 105)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('comparaison_user4_user9_par_type.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Distribution des types d'annotations (camembert des top 10)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    top_types = df['CL'].value_counts().head(10)\n",
    "    other_count = df['CL'].value_counts().iloc[10:].sum()\n",
    "    \n",
    "    if other_count > 0:\n",
    "        labels = list(top_types.index) + ['Autres']\n",
    "        sizes = list(top_types.values) + [other_count]\n",
    "    else:\n",
    "        labels = list(top_types.index)\n",
    "        sizes = list(top_types.values)\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))\n",
    "    \n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title('Distribution des types d\\'annotations (Top 10 + Autres)', fontsize=14)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('distribution_types_annotations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Visualisations créées:\")\n",
    "    print(\"- taux_validation_par_type.png\")\n",
    "    print(\"- comparaison_user4_user9_par_type.png\") \n",
    "    print(\"- distribution_types_annotations.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CELLULE 8: Fonction principale d'analyse par type\n",
    "def main_annotation_type_analysis():\n",
    "    \"\"\"\n",
    "    Fonction principale pour l'analyse par type d'annotation\n",
    "    \"\"\"\n",
    "    print(\"ANALYSE COMPLÈTE PAR TYPE D'ANNOTATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Exécuter toutes les analyses par type\n",
    "    global_type_stats = analyze_annotation_types_global(df)\n",
    "    user_type_stats = analyze_annotation_types_by_user(df, ['User4', 'User9'])\n",
    "    validation_rates = analyze_annotation_types_validation_rates(df)\n",
    "    user_performance = analyze_user_performance_by_annotation_type(df, ['User4', 'User9'])\n",
    "    comparison = compare_annotation_types_between_users(df, 'User4', 'User9')\n",
    "    validator_analysis = analyze_annotation_types_by_validator(df, ['User4', 'User9'])\n",
    "    \n",
    "    # Regrouper les résultats\n",
    "    results = {\n",
    "        'global_type_stats': global_type_stats,\n",
    "        'user_type_stats': user_type_stats,\n",
    "        'validation_rates': validation_rates,\n",
    "        'user_performance': user_performance,\n",
    "        'comparison': comparison,\n",
    "        'validator_analysis': validator_analysis\n",
    "    }\n",
    "    \n",
    "    # Créer les visualisations\n",
    "    create_annotation_type_visualizations(df, results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYSE PAR TYPE D'ANNOTATION TERMINÉE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSE COMPLÈTE PAR TYPE D'ANNOTATION\n",
      "============================================================\n",
      "==================================================\n",
      "ANALYSE GLOBALE DES TYPES D'ANNOTATIONS\n",
      "==================================================\n",
      "Nombre total de types d'annotations: 25\n",
      "Total des annotations: 2253\n",
      "\n",
      "Top 10 des types les plus fréquents:\n",
      "   1. Macrophages: 394 annotations (97.72% OK)\n",
      "   2. Peri. mono. infiltr. (A Grade): 338 annotations (72.49% OK)\n",
      "   3. Large airway lymphocytic inflammation: 105 annotations (96.19% OK)\n",
      "   4. Hemosiderosis: 90 annotations (97.78% OK)\n",
      "   5. Other: 87 annotations (73.56% OK)\n",
      "   6. Gran. tissue plugs in alveolar spaces: 68 annotations (91.18% OK)\n",
      "   7. BALT: 64 annotations (81.25% OK)\n",
      "   8. Pneu. hypertr. / react. chang.: 58 annotations (100.00% OK)\n",
      "   9. Fibrin balls in alveolar spaces: 38 annotations (52.63% OK)\n",
      "  10. Neutrophils in alveolar septa: 36 annotations (80.56% OK)\n",
      "============================================================\n",
      "ANALYSE DES TYPES D'ANNOTATIONS PAR User4 ET User9\n",
      "============================================================\n",
      "\n",
      "--- Analyse pour User4 ---\n",
      "Nombre de types annotés par User4: 12\n",
      "Total des annotations par User4: 89\n",
      "\n",
      "Top 10 des types annotés par User4:\n",
      "   1. Fibrin balls in alveolar spaces: 26 annotations (34.62% OK)\n",
      "   2. Peri. mono. infiltr. (A Grade): 17 annotations (94.12% OK)\n",
      "   3. Pneu. hypertr. / react. chang.: 12 annotations (100.00% OK)\n",
      "   4. Macrophages: 10 annotations (100.00% OK)\n",
      "   5. BALT: 7 annotations (57.14% OK)\n",
      "   6. Neutrophils in alveolar septa: 5 annotations (100.00% OK)\n",
      "   7. Septal fibrous thickening: 4 annotations (75.00% OK)\n",
      "   8. Gran. tissue plugs in alveolar spaces: 4 annotations (100.00% OK)\n",
      "   9. Other: 1 annotations (0.00% OK)\n",
      "  10. Large airway lymphocytic inflammation: 1 annotations (100.00% OK)\n",
      "\n",
      "--- Analyse pour User9 ---\n",
      "Nombre de types annotés par User9: 6\n",
      "Total des annotations par User9: 59\n",
      "\n",
      "Top 10 des types annotés par User9:\n",
      "   1. Peri. mono. infiltr. (A Grade): 28 annotations (89.29% OK)\n",
      "   2. Macrophages: 11 annotations (100.00% OK)\n",
      "   3. Neutrophils in alveolar septa: 9 annotations (88.89% OK)\n",
      "   4. BALT: 7 annotations (100.00% OK)\n",
      "   5. Pneu. hypertr. / react. chang.: 3 annotations (100.00% OK)\n",
      "   6. Fibrin balls in alveolar spaces: 1 annotations (0.00% OK)\n",
      "==================================================\n",
      "TAUX DE VALIDATION PAR TYPE D'ANNOTATION\n",
      "==================================================\n",
      "Types d'annotations avec les MEILLEURS taux de validation (≥10 annotations):\n",
      "   1. Pneu. hypertr. / react. chang.: 100.00% OK (58 total)\n",
      "   2. Infiltration by neutrophils: 100.00% OK (24 total)\n",
      "   3. Septal widening: 100.00% OK (11 total)\n",
      "   4. Hemosiderosis: 97.78% OK (90 total)\n",
      "   5. Macrophages: 97.72% OK (394 total)\n",
      "   6. Large airway lymphocytic inflammation: 96.19% OK (105 total)\n",
      "   7. Gran. tissue plugs in alveolar spaces: 91.18% OK (68 total)\n",
      "   8. Alveolar capillary dilatation: 90.91% OK (33 total)\n",
      "   9. Septal fibrous thickening: 89.47% OK (19 total)\n",
      "  10. BALT: 81.25% OK (64 total)\n",
      "\n",
      "Types d'annotations avec les PLUS FAIBLES taux de validation (≥10 annotations):\n",
      "   1. Septal fibrous thickening: 89.47% OK (19 total)\n",
      "   2. BALT: 81.25% OK (64 total)\n",
      "   3. Neutrophils in alveolar septa: 80.56% OK (36 total)\n",
      "   4. Other: 73.56% OK (87 total)\n",
      "   5. Peri. mono. infiltr. (A Grade): 72.49% OK (338 total)\n",
      "   6. Infiltr. by mononucl. cells: 70.00% OK (10 total)\n",
      "   7. Mononucl. cells in alveolar septa: 63.64% OK (11 total)\n",
      "   8. Fibrin balls in alveolar spaces: 52.63% OK (38 total)\n",
      "   9. Obliterative bronchiolitis (C Grade): 7.69% OK (13 total)\n",
      "  10. Lym. bronch. (B Grade): 5.00% OK (20 total)\n",
      "============================================================\n",
      "PERFORMANCE DE User4 ET User9 PAR TYPE D'ANNOTATION\n",
      "============================================================\n",
      "\n",
      "--- Performance de User4 par type ---\n",
      "Meilleure performance de User4 (≥5 annotations par type):\n",
      "  1. Pneu. hypertr. / react. chang.: 100.00% OK (12 total)\n",
      "  2. Macrophages: 100.00% OK (10 total)\n",
      "  3. Neutrophils in alveolar septa: 100.00% OK (5 total)\n",
      "  4. Peri. mono. infiltr. (A Grade): 94.12% OK (17 total)\n",
      "  5. BALT: 57.14% OK (7 total)\n",
      "\n",
      "Plus faible performance de User4:\n",
      "  1. Macrophages: 100.00% OK (10 total)\n",
      "  2. Neutrophils in alveolar septa: 100.00% OK (5 total)\n",
      "  3. Peri. mono. infiltr. (A Grade): 94.12% OK (17 total)\n",
      "  4. BALT: 57.14% OK (7 total)\n",
      "  5. Fibrin balls in alveolar spaces: 34.62% OK (26 total)\n",
      "\n",
      "--- Performance de User9 par type ---\n",
      "Meilleure performance de User9 (≥5 annotations par type):\n",
      "  1. Macrophages: 100.00% OK (11 total)\n",
      "  2. BALT: 100.00% OK (7 total)\n",
      "  3. Peri. mono. infiltr. (A Grade): 89.29% OK (28 total)\n",
      "  4. Neutrophils in alveolar septa: 88.89% OK (9 total)\n",
      "============================================================\n",
      "COMPARAISON User4 vs User9 PAR TYPE D'ANNOTATION\n",
      "============================================================\n",
      "Types d'annotations communs entre User4 et User9 (≥3 par utilisateur): 5\n",
      "\n",
      "Plus grandes différences de performance entre User4 et User9:\n",
      "   1. BALT:\n",
      "      User4: 57.1% OK (7 total)\n",
      "      User9: 100.0% OK (7 total)\n",
      "      Différence: 42.9% (avantage User9)\n",
      "   2. Neutrophils in alveolar septa:\n",
      "      User4: 100.0% OK (5 total)\n",
      "      User9: 88.9% OK (9 total)\n",
      "      Différence: 11.1% (avantage User4)\n",
      "   3. Peri. mono. infiltr. (A Grade):\n",
      "      User4: 94.1% OK (17 total)\n",
      "      User9: 89.3% OK (28 total)\n",
      "      Différence: 4.8% (avantage User4)\n",
      "   4. Macrophages:\n",
      "      User4: 100.0% OK (10 total)\n",
      "      User9: 100.0% OK (11 total)\n",
      "      Différence: 0.0% (avantage User9)\n",
      "   5. Pneu. hypertr. / react. chang.:\n",
      "      User4: 100.0% OK (12 total)\n",
      "      User9: 100.0% OK (3 total)\n",
      "      Différence: 0.0% (avantage User9)\n",
      "============================================================\n",
      "VALIDATIONS PAR TYPE - VALIDATEURS User4 ET User9\n",
      "============================================================\n",
      "\n",
      "--- Validations par User4 ---\n",
      "Nombre de types validés par User4: 16\n",
      "Total des validations par User4: 268\n",
      "\n",
      "Top 10 des types validés par User4:\n",
      "   1. Peri. mono. infiltr. (A Grade): 103 validations (37.86% OK)\n",
      "   2. Macrophages: 87 validations (98.85% OK)\n",
      "   3. Large airway lymphocytic inflammation: 25 validations (100.00% OK)\n",
      "   4. Lym. bronch. (B Grade): 16 validations (0.00% OK)\n",
      "   5. Pneu. hypertr. / react. chang.: 7 validations (100.00% OK)\n",
      "   6. Hemosiderosis: 5 validations (100.00% OK)\n",
      "   7. Ischemic necrosis: 5 validations (100.00% OK)\n",
      "   8. Alveolar capillary dilatation: 4 validations (50.00% OK)\n",
      "   9. Neutrophils in alveolar septa: 4 validations (0.00% OK)\n",
      "  10. Mononucl. cells in alveolar septa: 3 validations (66.67% OK)\n",
      "\n",
      "--- Validations par User9 ---\n",
      "Nombre de types validés par User9: 17\n",
      "Total des validations par User9: 260\n",
      "\n",
      "Top 10 des types validés par User9:\n",
      "   1. Large airway lymphocytic inflammation: 60 validations (95.00% OK)\n",
      "   2. Macrophages: 30 validations (96.67% OK)\n",
      "   3. Hemosiderosis: 29 validations (100.00% OK)\n",
      "   4. Gran. tissue plugs in alveolar spaces: 22 validations (81.82% OK)\n",
      "   5. BALT: 22 validations (77.27% OK)\n",
      "   6. Other: 21 validations (42.86% OK)\n",
      "   7. Peri. mono. infiltr. (A Grade): 21 validations (95.24% OK)\n",
      "   8. Pneu. hypertr. / react. chang.: 20 validations (100.00% OK)\n",
      "   9. Alveolar capillary dilatation: 8 validations (87.50% OK)\n",
      "  10. Arteritis/ endotheliitis/ vessel remodelling: 6 validations (100.00% OK)\n",
      "==================================================\n",
      "CRÉATION DES VISUALISATIONS PAR TYPE\n",
      "==================================================\n",
      "Visualisations créées:\n",
      "- taux_validation_par_type.png\n",
      "- comparaison_user4_user9_par_type.png\n",
      "- distribution_types_annotations.png\n",
      "\n",
      "============================================================\n",
      "ANALYSE PAR TYPE D'ANNOTATION TERMINÉE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CELLULE 9: Exécution de l'analyse complète par type\n",
    "# Exécuter l'analyse complète par type d'annotation\n",
    "type_analysis_results = main_annotation_type_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_user4_user9_visualizations(df):\n",
    "    \"\"\"\n",
    "    Créer des visualisations avancées spécifiquement pour User4 et User9\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CRÉATION DES VISUALISATIONS AVANCÉES POUR USER4 ET USER9\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Configuration générale\n",
    "    plt.style.use('ggplot')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Préparation des données\n",
    "    user4_df = df[df['USER'] == 'User4'].copy()\n",
    "    user9_df = df[df['USER'] == 'User9'].copy()\n",
    "    \n",
    "    # 1. HEATMAP DE PERFORMANCE PAR TYPE D'ANNOTATION\n",
    "    print(\"1. Création de la heatmap de performance par type...\")\n",
    "    \n",
    "    # Calculer les performances par type pour chaque utilisateur\n",
    "    def get_user_type_performance(user_df, min_annotations=2):\n",
    "        type_performance = {}\n",
    "        for annotation_type in user_df['CL'].value_counts().index:\n",
    "            type_data = user_df[user_df['CL'] == annotation_type]\n",
    "            if len(type_data) >= min_annotations:\n",
    "                ok_rate = (len(type_data[type_data['STATUS'] == 'OK']) / len(type_data)) * 100\n",
    "                type_performance[annotation_type] = ok_rate\n",
    "        return type_performance\n",
    "    \n",
    "    user4_performance = get_user_type_performance(user4_df)\n",
    "    user9_performance = get_user_type_performance(user9_df)\n",
    "    \n",
    "    # Créer une matrice de performance\n",
    "    all_types = set(user4_performance.keys()) | set(user9_performance.keys())\n",
    "    performance_matrix = []\n",
    "    type_labels = []\n",
    "    \n",
    "    for annotation_type in sorted(all_types):\n",
    "        if annotation_type in user4_performance and annotation_type in user9_performance:\n",
    "            performance_matrix.append([\n",
    "                user4_performance[annotation_type],\n",
    "                user9_performance[annotation_type]\n",
    "            ])\n",
    "            type_labels.append(annotation_type[:25] + \"...\" if len(annotation_type) > 25 else annotation_type)\n",
    "    \n",
    "    if performance_matrix:\n",
    "        plt.figure(figsize=(10, max(8, len(type_labels) * 0.4)))\n",
    "        \n",
    "        performance_matrix = np.array(performance_matrix)\n",
    "        \n",
    "        # Créer la heatmap\n",
    "        ax = sns.heatmap(performance_matrix, \n",
    "                        xticklabels=['User4', 'User9'],\n",
    "                        yticklabels=type_labels,\n",
    "                        annot=True, \n",
    "                        fmt='.1f',\n",
    "                        cmap='RdYlGn',\n",
    "                        center=80,\n",
    "                        cbar_kws={'label': 'Taux de validation (%)'})\n",
    "        \n",
    "        plt.title('Heatmap des performances User4 vs User9 par type d\\'annotation', fontsize=14, pad=20)\n",
    "        plt.xlabel('Utilisateur', fontsize=12)\n",
    "        plt.ylabel('Type d\\'annotation', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('heatmap_user4_user9_performance.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. GRAPHIQUE RADAR DES PERFORMANCES\n",
    "    print(\"2. Création du graphique radar...\")\n",
    "    \n",
    "    # Sélectionner les types les plus fréquents communs\n",
    "    common_types = []\n",
    "    for t in user4_df['CL'].value_counts().index[:10]:\n",
    "        if t in user9_df['CL'].value_counts().index and \\\n",
    "           len(user4_df[user4_df['CL'] == t]) >= 3 and \\\n",
    "           len(user9_df[user9_df['CL'] == t]) >= 3:\n",
    "            common_types.append(t)\n",
    "    \n",
    "    if len(common_types) >= 3:\n",
    "        # Calculer les performances pour le radar\n",
    "        user4_radar_data = []\n",
    "        user9_radar_data = []\n",
    "        radar_labels = []\n",
    "        \n",
    "        for annotation_type in common_types[:8]:  # Maximum 8 pour lisibilité\n",
    "            user4_type_data = user4_df[user4_df['CL'] == annotation_type]\n",
    "            user9_type_data = user9_df[user9_df['CL'] == annotation_type]\n",
    "            \n",
    "            user4_rate = (len(user4_type_data[user4_type_data['STATUS'] == 'OK']) / len(user4_type_data)) * 100\n",
    "            user9_rate = (len(user9_type_data[user9_type_data['STATUS'] == 'OK']) / len(user9_type_data)) * 100\n",
    "            \n",
    "            user4_radar_data.append(user4_rate)\n",
    "            user9_radar_data.append(user9_rate)\n",
    "            radar_labels.append(annotation_type[:15] + \"...\" if len(annotation_type) > 15 else annotation_type)\n",
    "        \n",
    "        # Créer le graphique radar\n",
    "        angles = np.linspace(0, 2 * np.pi, len(radar_labels), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Fermer le cercle\n",
    "        \n",
    "        user4_radar_data += user4_radar_data[:1]\n",
    "        user9_radar_data += user9_radar_data[:1]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "        \n",
    "        ax.plot(angles, user4_radar_data, 'o-', linewidth=2, label='User4', color='blue')\n",
    "        ax.fill(angles, user4_radar_data, alpha=0.25, color='blue')\n",
    "        \n",
    "        ax.plot(angles, user9_radar_data, 'o-', linewidth=2, label='User9', color='green')\n",
    "        ax.fill(angles, user9_radar_data, alpha=0.25, color='green')\n",
    "        \n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(radar_labels)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_ylabel('Taux de validation (%)', labelpad=30)\n",
    "        ax.set_title('Comparaison radar User4 vs User9\\\\npar type d\\'annotation', pad=30, fontsize=14)\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "        ax.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('radar_user4_user9_performance.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. GRAPHIQUE EN BARRES EMPILÉES - VOLUME ET PERFORMANCE\n",
    "    print(\"3. Création du graphique en barres empilées...\")\n",
    "    \n",
    "    # Top 10 des types les plus annotés par User4 et User9\n",
    "    user4_top_types = user4_df['CL'].value_counts().head(10)\n",
    "    user9_top_types = user9_df['CL'].value_counts().head(10)\n",
    "    all_top_types = set(user4_top_types.index) | set(user9_top_types.index)\n",
    "    \n",
    "    # Préparer les données pour le graphique empilé\n",
    "    types_data = []\n",
    "    for annotation_type in all_top_types:\n",
    "        user4_type_data = user4_df[user4_df['CL'] == annotation_type]\n",
    "        user9_type_data = user9_df[user9_df['CL'] == annotation_type]\n",
    "        \n",
    "        user4_total = len(user4_type_data)\n",
    "        user4_ok = len(user4_type_data[user4_type_data['STATUS'] == 'OK'])\n",
    "        user4_nok = user4_total - user4_ok\n",
    "        \n",
    "        user9_total = len(user9_type_data)\n",
    "        user9_ok = len(user9_type_data[user9_type_data['STATUS'] == 'OK'])\n",
    "        user9_nok = user9_total - user9_ok\n",
    "        \n",
    "        if user4_total > 0 or user9_total > 0:\n",
    "            types_data.append({\n",
    "                'type': annotation_type,\n",
    "                'user4_ok': user4_ok,\n",
    "                'user4_nok': user4_nok,\n",
    "                'user9_ok': user9_ok,\n",
    "                'user9_nok': user9_nok,\n",
    "                'total': user4_total + user9_total\n",
    "            })\n",
    "    \n",
    "    # Trier par volume total\n",
    "    types_data.sort(key=lambda x: x['total'], reverse=True)\n",
    "    types_data = types_data[:12]  # Top 12\n",
    "    \n",
    "    if types_data:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        type_names = [item['type'][:20] + \"...\" if len(item['type']) > 20 else item['type'] for item in types_data]\n",
    "        \n",
    "        # Graphique User4\n",
    "        user4_ok_counts = [item['user4_ok'] for item in types_data]\n",
    "        user4_nok_counts = [item['user4_nok'] for item in types_data]\n",
    "        \n",
    "        x = np.arange(len(type_names))\n",
    "        ax1.bar(x, user4_ok_counts, label='OK', color='lightgreen', alpha=0.8)\n",
    "        ax1.bar(x, user4_nok_counts, bottom=user4_ok_counts, label='NOK', color='lightcoral', alpha=0.8)\n",
    "        \n",
    "        ax1.set_title('User4 - Volume et statut par type', fontsize=12)\n",
    "        ax1.set_xlabel('Type d\\'annotation')\n",
    "        ax1.set_ylabel('Nombre d\\'annotations')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(type_names, rotation=45, ha='right')\n",
    "        ax1.legend()\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Graphique User9\n",
    "        user9_ok_counts = [item['user9_ok'] for item in types_data]\n",
    "        user9_nok_counts = [item['user9_nok'] for item in types_data]\n",
    "        \n",
    "        ax2.bar(x, user9_ok_counts, label='OK', color='lightgreen', alpha=0.8)\n",
    "        ax2.bar(x, user9_nok_counts, bottom=user9_ok_counts, label='NOK', color='lightcoral', alpha=0.8)\n",
    "        \n",
    "        ax2.set_title('User9 - Volume et statut par type', fontsize=12)\n",
    "        ax2.set_xlabel('Type d\\'annotation')\n",
    "        ax2.set_ylabel('Nombre d\\'annotations')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(type_names, rotation=45, ha='right')\n",
    "        ax2.legend()\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('barres_empilees_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 4. SCATTER PLOT - VOLUME vs PERFORMANCE\n",
    "    print(\"4. Création du scatter plot volume vs performance...\")\n",
    "    \n",
    "    # Préparer les données pour scatter plot\n",
    "    scatter_data = []\n",
    "    for annotation_type in df['CL'].unique():\n",
    "        user4_type_data = user4_df[user4_df['CL'] == annotation_type]\n",
    "        user9_type_data = user9_df[user9_df['CL'] == annotation_type]\n",
    "        \n",
    "        if len(user4_type_data) > 0:\n",
    "            user4_rate = (len(user4_type_data[user4_type_data['STATUS'] == 'OK']) / len(user4_type_data)) * 100\n",
    "            scatter_data.append({\n",
    "                'user': 'User4',\n",
    "                'type': annotation_type,\n",
    "                'volume': len(user4_type_data),\n",
    "                'performance': user4_rate\n",
    "            })\n",
    "        \n",
    "        if len(user9_type_data) > 0:\n",
    "            user9_rate = (len(user9_type_data[user9_type_data['STATUS'] == 'OK']) / len(user9_type_data)) * 100\n",
    "            scatter_data.append({\n",
    "                'user': 'User9',\n",
    "                'type': annotation_type,\n",
    "                'volume': len(user9_type_data),\n",
    "                'performance': user9_rate\n",
    "            })\n",
    "    \n",
    "    if scatter_data:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        user4_data = [item for item in scatter_data if item['user'] == 'User4']\n",
    "        user9_data = [item for item in scatter_data if item['user'] == 'User9']\n",
    "        \n",
    "        if user4_data:\n",
    "            user4_volumes = [item['volume'] for item in user4_data]\n",
    "            user4_performances = [item['performance'] for item in user4_data]\n",
    "            plt.scatter(user4_volumes, user4_performances, \n",
    "                       label='User4', alpha=0.7, s=100, color='blue')\n",
    "        \n",
    "        if user9_data:\n",
    "            user9_volumes = [item['volume'] for item in user9_data]\n",
    "            user9_performances = [item['performance'] for item in user9_data]\n",
    "            plt.scatter(user9_volumes, user9_performances, \n",
    "                       label='User9', alpha=0.7, s=100, color='green')\n",
    "        \n",
    "        plt.xlabel('Volume d\\'annotations par type', fontsize=12)\n",
    "        plt.ylabel('Taux de validation (%)', fontsize=12)\n",
    "        plt.title('Relation Volume vs Performance par type\\\\nUser4 vs User9', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(0, max([item['volume'] for item in scatter_data]) * 1.1)\n",
    "        plt.ylim(0, 105)\n",
    "        \n",
    "        # Ajouter une ligne de tendance pour chaque utilisateur\n",
    "        if user4_data and len(user4_data) > 1:\n",
    "            z = np.polyfit(user4_volumes, user4_performances, 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(sorted(user4_volumes), p(sorted(user4_volumes)), \"--\", alpha=0.8, color='blue')\n",
    "        \n",
    "        if user9_data and len(user9_data) > 1:\n",
    "            z = np.polyfit(user9_volumes, user9_performances, 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(sorted(user9_volumes), p(sorted(user9_volumes)), \"--\", alpha=0.8, color='green')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('scatter_volume_performance_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 5. GRAPHIQUE EN VIOLIN PLOT - DISTRIBUTION DES PERFORMANCES\n",
    "    print(\"5. Création des violin plots...\")\n",
    "    \n",
    "    # Préparer les données pour violin plot\n",
    "    performance_data = []\n",
    "    \n",
    "    for annotation_type in df['CL'].unique():\n",
    "        user4_type_data = user4_df[user4_df['CL'] == annotation_type]\n",
    "        user9_type_data = user9_df[user9_df['CL'] == annotation_type]\n",
    "        \n",
    "        if len(user4_type_data) >= 3:  # Au moins 3 annotations\n",
    "            user4_rate = (len(user4_type_data[user4_type_data['STATUS'] == 'OK']) / len(user4_type_data)) * 100\n",
    "            performance_data.extend([user4_rate] * len(user4_type_data))\n",
    "            performance_data.extend(['User4'] * len(user4_type_data))\n",
    "        \n",
    "        if len(user9_type_data) >= 3:  # Au moins 3 annotations\n",
    "            user9_rate = (len(user9_type_data[user9_type_data['STATUS'] == 'OK']) / len(user9_type_data)) * 100\n",
    "            performance_data.extend([user9_rate] * len(user9_type_data))\n",
    "            performance_data.extend(['User9'] * len(user9_type_data))\n",
    "    \n",
    "    # Reformater pour seaborn\n",
    "    if len(performance_data) > 0:\n",
    "        violin_df = pd.DataFrame({\n",
    "            'Performance': performance_data[::2],\n",
    "            'User': performance_data[1::2]\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.violinplot(data=violin_df, x='User', y='Performance', palette=['blue', 'green'])\n",
    "        sns.stripplot(data=violin_df, x='User', y='Performance', color='black', alpha=0.6, size=3)\n",
    "        \n",
    "        plt.title('Distribution des performances par utilisateur\\\\n(toutes annotations)', fontsize=14)\n",
    "        plt.ylabel('Taux de validation (%)', fontsize=12)\n",
    "        plt.xlabel('Utilisateur', fontsize=12)\n",
    "        plt.ylim(0, 105)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('violin_plot_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 6. MATRICE DE CONFUSION COMPARATIVE\n",
    "    print(\"6. Création de la matrice de confusion comparative...\")\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # User4 comme annotateur\n",
    "    user4_annotator_data = df[df['USER'] == 'User4']\n",
    "    if len(user4_annotator_data) > 0:\n",
    "        user4_status_counts = user4_annotator_data['STATUS'].value_counts()\n",
    "        labels = ['OK', 'NOK']\n",
    "        sizes = [user4_status_counts.get('OK', 0), user4_status_counts.get('NOK', 0)]\n",
    "        colors = ['lightgreen', 'lightcoral']\n",
    "        \n",
    "        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax1.set_title(f'User4 comme annotateur\\\\n({len(user4_annotator_data)} annotations)')\n",
    "    \n",
    "    # User9 comme annotateur\n",
    "    user9_annotator_data = df[df['USER'] == 'User9']\n",
    "    if len(user9_annotator_data) > 0:\n",
    "        user9_status_counts = user9_annotator_data['STATUS'].value_counts()\n",
    "        sizes = [user9_status_counts.get('OK', 0), user9_status_counts.get('NOK', 0)]\n",
    "        \n",
    "        ax2.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax2.set_title(f'User9 comme annotateur\\\\n({len(user9_annotator_data)} annotations)')\n",
    "    \n",
    "    # User4 comme validateur\n",
    "    user4_validator_data = df[df['USER_VALIDATOR'] == 'User4']\n",
    "    if len(user4_validator_data) > 0:\n",
    "        user4_val_status_counts = user4_validator_data['STATUS'].value_counts()\n",
    "        sizes = [user4_val_status_counts.get('OK', 0), user4_val_status_counts.get('NOK', 0)]\n",
    "        \n",
    "        ax3.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax3.set_title(f'User4 comme validateur\\\\n({len(user4_validator_data)} validations)')\n",
    "    \n",
    "    # User9 comme validateur\n",
    "    user9_validator_data = df[df['USER_VALIDATOR'] == 'User9']\n",
    "    if len(user9_validator_data) > 0:\n",
    "        user9_val_status_counts = user9_validator_data['STATUS'].value_counts()\n",
    "        sizes = [user9_val_status_counts.get('OK', 0), user9_val_status_counts.get('NOK', 0)]\n",
    "        \n",
    "        ax4.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax4.set_title(f'User9 comme validateur\\\\n({len(user9_validator_data)} validations)')\n",
    "    \n",
    "    plt.suptitle('Matrices de confusion User4 vs User9\\\\nAnnotateur vs Validateur', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('matrices_confusion_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 7. GRAPHIQUE TEMPOREL (si possible avec les IDs comme proxy)\n",
    "    print(\"7. Création du graphique de progression...\")\n",
    "    \n",
    "    # Utiliser les IDs comme proxy temporel\n",
    "    user4_df_sorted = user4_df.sort_values('ID')\n",
    "    user9_df_sorted = user9_df.sort_values('ID')\n",
    "    \n",
    "    # Calculer les moyennes mobiles\n",
    "    def calculate_moving_average(df, window=10):\n",
    "        df['STATUS_NUMERIC'] = df['STATUS'].map({'OK': 1, 'NOK': 0})\n",
    "        df['MOVING_AVG'] = df['STATUS_NUMERIC'].rolling(window=window, min_periods=1).mean() * 100\n",
    "        return df\n",
    "    \n",
    "    if len(user4_df_sorted) >= 5:\n",
    "        user4_df_sorted = calculate_moving_average(user4_df_sorted)\n",
    "    if len(user9_df_sorted) >= 5:\n",
    "        user9_df_sorted = calculate_moving_average(user9_df_sorted)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if len(user4_df_sorted) >= 5:\n",
    "        plt.plot(range(len(user4_df_sorted)), user4_df_sorted['MOVING_AVG'], \n",
    "                label='User4 (moyenne mobile)', linewidth=2, color='blue')\n",
    "        plt.scatter(range(len(user4_df_sorted)), user4_df_sorted['STATUS_NUMERIC'] * 100, \n",
    "                   alpha=0.3, s=20, color='blue')\n",
    "    \n",
    "    if len(user9_df_sorted) >= 5:\n",
    "        plt.plot(range(len(user9_df_sorted)), user9_df_sorted['MOVING_AVG'], \n",
    "                label='User9 (moyenne mobile)', linewidth=2, color='green')\n",
    "        plt.scatter(range(len(user9_df_sorted)), user9_df_sorted['STATUS_NUMERIC'] * 100, \n",
    "                   alpha=0.3, s=20, color='green')\n",
    "    \n",
    "    plt.xlabel('Ordre d\\'annotation (basé sur ID)', fontsize=12)\n",
    "    plt.ylabel('Taux de validation (%)', fontsize=12)\n",
    "    plt.title('Évolution de la performance au fil des annotations\\\\nUser4 vs User9', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(-5, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('evolution_performance_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 8. COMPARAISON DES SPÉCIALITÉS\n",
    "    print(\"8. Création du graphique des spécialités...\")\n",
    "    \n",
    "    # Identifier les types où chaque utilisateur excelle\n",
    "    user4_specialties = []\n",
    "    user9_specialties = []\n",
    "    \n",
    "    for annotation_type in df['CL'].unique():\n",
    "        user4_type_data = user4_df[user4_df['CL'] == annotation_type]\n",
    "        user9_type_data = user9_df[user9_df['CL'] == annotation_type]\n",
    "        \n",
    "        if len(user4_type_data) >= 3 and len(user9_type_data) >= 3:\n",
    "            user4_rate = (len(user4_type_data[user4_type_data['STATUS'] == 'OK']) / len(user4_type_data)) * 100\n",
    "            user9_rate = (len(user9_type_data[user9_type_data['STATUS'] == 'OK']) / len(user9_type_data)) * 100\n",
    "            \n",
    "            if user4_rate > user9_rate + 10:  # Au moins 10% de différence\n",
    "                user4_specialties.append((annotation_type, user4_rate - user9_rate))\n",
    "            elif user9_rate > user4_rate + 10:\n",
    "                user9_specialties.append((annotation_type, user9_rate - user4_rate))\n",
    "    \n",
    "    # Créer le graphique des spécialités\n",
    "    if user4_specialties or user9_specialties:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        \n",
    "        if user4_specialties:\n",
    "            user4_specialties.sort(key=lambda x: x[1], reverse=True)\n",
    "            types = [item[0][:20] + \"...\" if len(item[0]) > 20 else item[0] for item in user4_specialties[:5]]\n",
    "            differences = [item[1] for item in user4_specialties[:5]]\n",
    "            \n",
    "            bars = ax1.barh(range(len(types)), differences, color='blue', alpha=0.7)\n",
    "            ax1.set_yticks(range(len(types)))\n",
    "            ax1.set_yticklabels(types)\n",
    "            ax1.set_xlabel('Avantage sur User9 (%)')\n",
    "            ax1.set_title('Spécialités de User4\\\\n(Types où User4 > User9 + 10%)')\n",
    "            ax1.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # Ajouter les valeurs\n",
    "            for i, bar in enumerate(bars):\n",
    "                width = bar.get_width()\n",
    "                ax1.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                        f'+{width:.1f}%', ha='left', va='center')\n",
    "        \n",
    "        if user9_specialties:\n",
    "            user9_specialties.sort(key=lambda x: x[1], reverse=True)\n",
    "            types = [item[0][:20] + \"...\" if len(item[0]) > 20 else item[0] for item in user9_specialties[:5]]\n",
    "            differences = [item[1] for item in user9_specialties[:5]]\n",
    "            \n",
    "            bars = ax2.barh(range(len(types)), differences, color='green', alpha=0.7)\n",
    "            ax2.set_yticks(range(len(types)))\n",
    "            ax2.set_yticklabels(types)\n",
    "            ax2.set_xlabel('Avantage sur User4 (%)')\n",
    "            ax2.set_title('Spécialités de User9\\\\n(Types où User9 > User4 + 10%)')\n",
    "            ax2.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # Ajouter les valeurs\n",
    "            for i, bar in enumerate(bars):\n",
    "                width = bar.get_width()\n",
    "                ax2.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                        f'+{width:.1f}%', ha='left', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('specialites_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VISUALISATIONS AVANCÉES CRÉÉES:\")\n",
    "    print(\"- heatmap_user4_user9_performance.png\")\n",
    "    print(\"- radar_user4_user9_performance.png\")\n",
    "    print(\"- barres_empilees_user4_user9.png\")\n",
    "    print(\"- scatter_volume_performance_user4_user9.png\")\n",
    "    print(\"- violin_plot_user4_user9.png\")\n",
    "    print(\"- matrices_confusion_user4_user9.png\")\n",
    "    print(\"- evolution_performance_user4_user9.png\")\n",
    "    print(\"- specialites_user4_user9.png\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "def create_comparative_analysis_dashboard(df):\n",
    "    \"\"\"\n",
    "    Créer un dashboard complet d'analyse comparative\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CRÉATION DU DASHBOARD COMPARATIF USER4 vs USER9\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Créer une figure avec multiple subplots\n",
    "    fig = plt.figure(figsize=(20, 24))\n",
    "    \n",
    "    user4_df = df[df['USER'] == 'User4']\n",
    "    user9_df = df[df['USER'] == 'User9']\n",
    "    \n",
    "    # 1. Statistiques générales (subplot 1)\n",
    "    ax1 = plt.subplot(4, 2, 1)\n",
    "    users = ['User4', 'User9']\n",
    "    total_annotations = [len(user4_df), len(user9_df)]\n",
    "    ok_annotations = [len(user4_df[user4_df['STATUS'] == 'OK']), \n",
    "                      len(user9_df[user9_df['STATUS'] == 'OK'])]\n",
    "    \n",
    "    x = np.arange(len(users))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, total_annotations, width, label='Total', alpha=0.8, color='lightblue')\n",
    "    ax1.bar(x + width/2, ok_annotations, width, label='OK', alpha=0.8, color='lightgreen')\n",
    "    \n",
    "    ax1.set_xlabel('Utilisateur')\n",
    "    ax1.set_ylabel('Nombre d\\'annotations')\n",
    "    ax1.set_title('Volume d\\'annotations - User4 vs User9')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(users)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Taux de validation (subplot 2)\n",
    "    ax2 = plt.subplot(4, 2, 2)\n",
    "    ok_rates = [(len(user4_df[user4_df['STATUS'] == 'OK']) / len(user4_df)) * 100,\n",
    "                (len(user9_df[user9_df['STATUS'] == 'OK']) / len(user9_df)) * 100]\n",
    "    \n",
    "    bars = ax2.bar(users, ok_rates, color=['blue', 'green'], alpha=0.7)\n",
    "    ax2.set_ylabel('Taux de validation (%)')\n",
    "    ax2.set_title('Taux de validation - User4 vs User9')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, rate in zip(bars, ok_rates):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Top 5 des types par utilisateur (subplot 3 et 4)\n",
    "    ax3 = plt.subplot(4, 2, 3)\n",
    "    user4_top_types = user4_df['CL'].value_counts().head(5)\n",
    "    ax3.barh(range(len(user4_top_types)), user4_top_types.values, color='blue', alpha=0.7)\n",
    "    ax3.set_yticks(range(len(user4_top_types)))\n",
    "    ax3.set_yticklabels([t[:25] + \"...\" if len(t) > 25 else t for t in user4_top_types.index])\n",
    "    ax3.set_xlabel('Nombre d\\'annotations')\n",
    "    ax3.set_title('Top 5 types - User4')\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    ax4 = plt.subplot(4, 2, 4)\n",
    "    user9_top_types = user9_df['CL'].value_counts().head(5)\n",
    "    ax4.barh(range(len(user9_top_types)), user9_top_types.values, color='green', alpha=0.7)\n",
    "    ax4.set_yticks(range(len(user9_top_types)))\n",
    "    ax4.set_yticklabels([t[:25] + \"...\" if len(t) > 25 else t for t in user9_top_types.index])\n",
    "    ax4.set_xlabel('Nombre d\\'annotations')\n",
    "    ax4.set_title('Top 5 types - User9')\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 5. Comparaison directe sur types communs (subplot 5-6)\n",
    "    ax5 = plt.subplot(4, 2, (5, 6))\n",
    "    \n",
    "    # Trouver les types communs significatifs\n",
    "    user4_types = set(user4_df['CL'].value_counts()[user4_df['CL'].value_counts() >= 3].index)\n",
    "    user9_types = set(user9_df['CL'].value_counts()[user9_df['CL'].value_counts() >= 3].index)\n",
    "    common_types = list(user4_types & user9_types)[:8]  # Top 8\n",
    "    \n",
    "    if common_types:\n",
    "        user4_rates = []\n",
    "        user9_rates = []\n",
    "        \n",
    "        for annotation_type in common_types:\n",
    "            user4_type_data = user4_df[user4_df['CL'] == annotation_type]\n",
    "            user9_type_data = user9_df[user9_df['CL'] == annotation_type]\n",
    "            \n",
    "            user4_rate = (len(user4_type_data[user4_type_data['STATUS'] == 'OK']) / len(user4_type_data)) * 100\n",
    "            user9_rate = (len(user9_type_data[user9_type_data['STATUS'] == 'OK']) / len(user9_type_data)) * 100\n",
    "            \n",
    "            user4_rates.append(user4_rate)\n",
    "            user9_rates.append(user9_rate)\n",
    "        \n",
    "        x = np.arange(len(common_types))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax5.bar(x - width/2, user4_rates, width, label='User4', color='blue', alpha=0.7)\n",
    "        ax5.bar(x + width/2, user9_rates, width, label='User9', color='green', alpha=0.7)\n",
    "        \n",
    "        ax5.set_xlabel('Type d\\'annotation')\n",
    "        ax5.set_ylabel('Taux de validation (%)')\n",
    "        ax5.set_title('Comparaison directe sur types communs')\n",
    "        ax5.set_xticks(x)\n",
    "        ax5.set_xticklabels([t[:15] + \"...\" if len(t) > 15 else t for t in common_types], \n",
    "                           rotation=45, ha='right')\n",
    "        ax5.legend()\n",
    "        ax5.grid(axis='y', alpha=0.3)\n",
    "        ax5.set_ylim(0, 105)\n",
    "    \n",
    "    # 7-8. Analyse des validateurs (subplot 7-8)\n",
    "    ax7 = plt.subplot(4, 2, 7)\n",
    "    user4_validator_df = df[df['USER_VALIDATOR'] == 'User4']\n",
    "    user9_validator_df = df[df['USER_VALIDATOR'] == 'User9']\n",
    "    \n",
    "    validator_stats = ['User4 validateur', 'User9 validateur']\n",
    "    validator_totals = [len(user4_validator_df), len(user9_validator_df)]\n",
    "    validator_ok_rates = []\n",
    "    \n",
    "    if len(user4_validator_df) > 0:\n",
    "        user4_val_rate = (len(user4_validator_df[user4_validator_df['STATUS'] == 'OK']) / len(user4_validator_df)) * 100\n",
    "        validator_ok_rates.append(user4_val_rate)\n",
    "    else:\n",
    "        validator_ok_rates.append(0)\n",
    "    \n",
    "    if len(user9_validator_df) > 0:\n",
    "        user9_val_rate = (len(user9_validator_df[user9_validator_df['STATUS'] == 'OK']) / len(user9_validator_df)) * 100\n",
    "        validator_ok_rates.append(user9_val_rate)\n",
    "    else:\n",
    "        validator_ok_rates.append(0)\n",
    "    \n",
    "    bars = ax7.bar(validator_stats, validator_ok_rates, color=['blue', 'green'], alpha=0.7)\n",
    "    ax7.set_ylabel('Taux de validation (%)')\n",
    "    ax7.set_title('Performance comme validateur')\n",
    "    ax7.set_ylim(0, 100)\n",
    "    ax7.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Ajouter les valeurs et volumes\n",
    "    for bar, rate, total in zip(bars, validator_ok_rates, validator_totals):\n",
    "        height = bar.get_height()\n",
    "        ax7.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{rate:.1f}%\\\\n({total} total)', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 8. Récapitulatif textuel (subplot 8)\n",
    "    ax8 = plt.subplot(4, 2, 8)\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    # Calculer quelques statistiques clés\n",
    "    user4_total = len(user4_df)\n",
    "    user4_ok_rate = (len(user4_df[user4_df['STATUS'] == 'OK']) / user4_total) * 100\n",
    "    user9_total = len(user9_df)\n",
    "    user9_ok_rate = (len(user9_df[user9_df['STATUS'] == 'OK']) / user9_total) * 100\n",
    "    \n",
    "    user4_types_count = len(user4_df['CL'].unique())\n",
    "    user9_types_count = len(user9_df['CL'].unique())\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "RÉSUMÉ COMPARATIF\n",
    "\n",
    "USER4:\n",
    "• {user4_total} annotations\n",
    "• {user4_ok_rate:.1f}% de taux de validation\n",
    "• {user4_types_count} types différents annotés\n",
    "• {len(user4_validator_df)} validations effectuées\n",
    "\n",
    "USER9:\n",
    "• {user9_total} annotations  \n",
    "• {user9_ok_rate:.1f}% de taux de validation\n",
    "• {user9_types_count} types différents annotés\n",
    "• {len(user9_validator_df)} validations effectuées\n",
    "\n",
    "DIFFÉRENCE:\n",
    "• Volume: {abs(user4_total - user9_total)} annotations\n",
    "• Performance: {abs(user4_ok_rate - user9_ok_rate):.1f}% d'écart\n",
    "• Meilleur: {'User4' if user4_ok_rate > user9_ok_rate else 'User9' if user9_ok_rate > user4_ok_rate else 'Égalité'}\n",
    "\"\"\"\n",
    "    \n",
    "    ax8.text(0.05, 0.95, summary_text, transform=ax8.transAxes, fontsize=11,\n",
    "             verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.5))\n",
    "    \n",
    "    plt.suptitle('DASHBOARD COMPARATIF USER4 vs USER9', fontsize=20, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.savefig('dashboard_comparatif_user4_user9.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Dashboard comparatif créé : dashboard_comparatif_user4_user9.png\")\n",
    "\n",
    "\n",
    "# CELLULE PRINCIPALE POUR EXÉCUTER TOUTES LES NOUVELLES VISUALISATIONS\n",
    "def execute_all_advanced_visualizations():\n",
    "    \"\"\"\n",
    "    Exécuter toutes les visualisations avancées pour User4 et User9\n",
    "    \"\"\"\n",
    "    print(\"EXÉCUTION DE TOUTES LES VISUALISATIONS AVANCÉES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Créer les visualisations avancées\n",
    "    create_advanced_user4_user9_visualizations(df)\n",
    "    \n",
    "    # Créer le dashboard comparatif\n",
    "    create_comparative_analysis_dashboard(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TOUTES LES VISUALISATIONS ONT ÉTÉ CRÉÉES AVEC SUCCÈS!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return \"Visualisations terminées\"\n",
    "\n",
    "# Pour exécuter toutes les nouvelles visualisations:\n",
    "# result = execute_all_advanced_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 LANCEMENT DE L'ANALYSE COMPLÈTE AVEC VISUALISATIONS AVANCÉES\n",
      "================================================================================\n",
      "\n",
      "📊 ÉTAPE 1: Analyse par type d'annotation\n",
      "ANALYSE COMPLÈTE PAR TYPE D'ANNOTATION\n",
      "============================================================\n",
      "==================================================\n",
      "ANALYSE GLOBALE DES TYPES D'ANNOTATIONS\n",
      "==================================================\n",
      "Nombre total de types d'annotations: 25\n",
      "Total des annotations: 2253\n",
      "\n",
      "Top 10 des types les plus fréquents:\n",
      "   1. Macrophages: 394 annotations (97.72% OK)\n",
      "   2. Peri. mono. infiltr. (A Grade): 338 annotations (72.49% OK)\n",
      "   3. Large airway lymphocytic inflammation: 105 annotations (96.19% OK)\n",
      "   4. Hemosiderosis: 90 annotations (97.78% OK)\n",
      "   5. Other: 87 annotations (73.56% OK)\n",
      "   6. Gran. tissue plugs in alveolar spaces: 68 annotations (91.18% OK)\n",
      "   7. BALT: 64 annotations (81.25% OK)\n",
      "   8. Pneu. hypertr. / react. chang.: 58 annotations (100.00% OK)\n",
      "   9. Fibrin balls in alveolar spaces: 38 annotations (52.63% OK)\n",
      "  10. Neutrophils in alveolar septa: 36 annotations (80.56% OK)\n",
      "============================================================\n",
      "ANALYSE DES TYPES D'ANNOTATIONS PAR User4 ET User9\n",
      "============================================================\n",
      "\n",
      "--- Analyse pour User4 ---\n",
      "Nombre de types annotés par User4: 12\n",
      "Total des annotations par User4: 89\n",
      "\n",
      "Top 10 des types annotés par User4:\n",
      "   1. Fibrin balls in alveolar spaces: 26 annotations (34.62% OK)\n",
      "   2. Peri. mono. infiltr. (A Grade): 17 annotations (94.12% OK)\n",
      "   3. Pneu. hypertr. / react. chang.: 12 annotations (100.00% OK)\n",
      "   4. Macrophages: 10 annotations (100.00% OK)\n",
      "   5. BALT: 7 annotations (57.14% OK)\n",
      "   6. Neutrophils in alveolar septa: 5 annotations (100.00% OK)\n",
      "   7. Septal fibrous thickening: 4 annotations (75.00% OK)\n",
      "   8. Gran. tissue plugs in alveolar spaces: 4 annotations (100.00% OK)\n",
      "   9. Other: 1 annotations (0.00% OK)\n",
      "  10. Large airway lymphocytic inflammation: 1 annotations (100.00% OK)\n",
      "\n",
      "--- Analyse pour User9 ---\n",
      "Nombre de types annotés par User9: 6\n",
      "Total des annotations par User9: 59\n",
      "\n",
      "Top 10 des types annotés par User9:\n",
      "   1. Peri. mono. infiltr. (A Grade): 28 annotations (89.29% OK)\n",
      "   2. Macrophages: 11 annotations (100.00% OK)\n",
      "   3. Neutrophils in alveolar septa: 9 annotations (88.89% OK)\n",
      "   4. BALT: 7 annotations (100.00% OK)\n",
      "   5. Pneu. hypertr. / react. chang.: 3 annotations (100.00% OK)\n",
      "   6. Fibrin balls in alveolar spaces: 1 annotations (0.00% OK)\n",
      "==================================================\n",
      "TAUX DE VALIDATION PAR TYPE D'ANNOTATION\n",
      "==================================================\n",
      "Types d'annotations avec les MEILLEURS taux de validation (≥10 annotations):\n",
      "   1. Pneu. hypertr. / react. chang.: 100.00% OK (58 total)\n",
      "   2. Infiltration by neutrophils: 100.00% OK (24 total)\n",
      "   3. Septal widening: 100.00% OK (11 total)\n",
      "   4. Hemosiderosis: 97.78% OK (90 total)\n",
      "   5. Macrophages: 97.72% OK (394 total)\n",
      "   6. Large airway lymphocytic inflammation: 96.19% OK (105 total)\n",
      "   7. Gran. tissue plugs in alveolar spaces: 91.18% OK (68 total)\n",
      "   8. Alveolar capillary dilatation: 90.91% OK (33 total)\n",
      "   9. Septal fibrous thickening: 89.47% OK (19 total)\n",
      "  10. BALT: 81.25% OK (64 total)\n",
      "\n",
      "Types d'annotations avec les PLUS FAIBLES taux de validation (≥10 annotations):\n",
      "   1. Septal fibrous thickening: 89.47% OK (19 total)\n",
      "   2. BALT: 81.25% OK (64 total)\n",
      "   3. Neutrophils in alveolar septa: 80.56% OK (36 total)\n",
      "   4. Other: 73.56% OK (87 total)\n",
      "   5. Peri. mono. infiltr. (A Grade): 72.49% OK (338 total)\n",
      "   6. Infiltr. by mononucl. cells: 70.00% OK (10 total)\n",
      "   7. Mononucl. cells in alveolar septa: 63.64% OK (11 total)\n",
      "   8. Fibrin balls in alveolar spaces: 52.63% OK (38 total)\n",
      "   9. Obliterative bronchiolitis (C Grade): 7.69% OK (13 total)\n",
      "  10. Lym. bronch. (B Grade): 5.00% OK (20 total)\n",
      "============================================================\n",
      "PERFORMANCE DE User4 ET User9 PAR TYPE D'ANNOTATION\n",
      "============================================================\n",
      "\n",
      "--- Performance de User4 par type ---\n",
      "Meilleure performance de User4 (≥5 annotations par type):\n",
      "  1. Pneu. hypertr. / react. chang.: 100.00% OK (12 total)\n",
      "  2. Macrophages: 100.00% OK (10 total)\n",
      "  3. Neutrophils in alveolar septa: 100.00% OK (5 total)\n",
      "  4. Peri. mono. infiltr. (A Grade): 94.12% OK (17 total)\n",
      "  5. BALT: 57.14% OK (7 total)\n",
      "\n",
      "Plus faible performance de User4:\n",
      "  1. Macrophages: 100.00% OK (10 total)\n",
      "  2. Neutrophils in alveolar septa: 100.00% OK (5 total)\n",
      "  3. Peri. mono. infiltr. (A Grade): 94.12% OK (17 total)\n",
      "  4. BALT: 57.14% OK (7 total)\n",
      "  5. Fibrin balls in alveolar spaces: 34.62% OK (26 total)\n",
      "\n",
      "--- Performance de User9 par type ---\n",
      "Meilleure performance de User9 (≥5 annotations par type):\n",
      "  1. Macrophages: 100.00% OK (11 total)\n",
      "  2. BALT: 100.00% OK (7 total)\n",
      "  3. Peri. mono. infiltr. (A Grade): 89.29% OK (28 total)\n",
      "  4. Neutrophils in alveolar septa: 88.89% OK (9 total)\n",
      "============================================================\n",
      "COMPARAISON User4 vs User9 PAR TYPE D'ANNOTATION\n",
      "============================================================\n",
      "Types d'annotations communs entre User4 et User9 (≥3 par utilisateur): 5\n",
      "\n",
      "Plus grandes différences de performance entre User4 et User9:\n",
      "   1. BALT:\n",
      "      User4: 57.1% OK (7 total)\n",
      "      User9: 100.0% OK (7 total)\n",
      "      Différence: 42.9% (avantage User9)\n",
      "   2. Neutrophils in alveolar septa:\n",
      "      User4: 100.0% OK (5 total)\n",
      "      User9: 88.9% OK (9 total)\n",
      "      Différence: 11.1% (avantage User4)\n",
      "   3. Peri. mono. infiltr. (A Grade):\n",
      "      User4: 94.1% OK (17 total)\n",
      "      User9: 89.3% OK (28 total)\n",
      "      Différence: 4.8% (avantage User4)\n",
      "   4. Macrophages:\n",
      "      User4: 100.0% OK (10 total)\n",
      "      User9: 100.0% OK (11 total)\n",
      "      Différence: 0.0% (avantage User9)\n",
      "   5. Pneu. hypertr. / react. chang.:\n",
      "      User4: 100.0% OK (12 total)\n",
      "      User9: 100.0% OK (3 total)\n",
      "      Différence: 0.0% (avantage User9)\n",
      "============================================================\n",
      "VALIDATIONS PAR TYPE - VALIDATEURS User4 ET User9\n",
      "============================================================\n",
      "\n",
      "--- Validations par User4 ---\n",
      "Nombre de types validés par User4: 16\n",
      "Total des validations par User4: 268\n",
      "\n",
      "Top 10 des types validés par User4:\n",
      "   1. Peri. mono. infiltr. (A Grade): 103 validations (37.86% OK)\n",
      "   2. Macrophages: 87 validations (98.85% OK)\n",
      "   3. Large airway lymphocytic inflammation: 25 validations (100.00% OK)\n",
      "   4. Lym. bronch. (B Grade): 16 validations (0.00% OK)\n",
      "   5. Pneu. hypertr. / react. chang.: 7 validations (100.00% OK)\n",
      "   6. Hemosiderosis: 5 validations (100.00% OK)\n",
      "   7. Ischemic necrosis: 5 validations (100.00% OK)\n",
      "   8. Alveolar capillary dilatation: 4 validations (50.00% OK)\n",
      "   9. Neutrophils in alveolar septa: 4 validations (0.00% OK)\n",
      "  10. Mononucl. cells in alveolar septa: 3 validations (66.67% OK)\n",
      "\n",
      "--- Validations par User9 ---\n",
      "Nombre de types validés par User9: 17\n",
      "Total des validations par User9: 260\n",
      "\n",
      "Top 10 des types validés par User9:\n",
      "   1. Large airway lymphocytic inflammation: 60 validations (95.00% OK)\n",
      "   2. Macrophages: 30 validations (96.67% OK)\n",
      "   3. Hemosiderosis: 29 validations (100.00% OK)\n",
      "   4. Gran. tissue plugs in alveolar spaces: 22 validations (81.82% OK)\n",
      "   5. BALT: 22 validations (77.27% OK)\n",
      "   6. Other: 21 validations (42.86% OK)\n",
      "   7. Peri. mono. infiltr. (A Grade): 21 validations (95.24% OK)\n",
      "   8. Pneu. hypertr. / react. chang.: 20 validations (100.00% OK)\n",
      "   9. Alveolar capillary dilatation: 8 validations (87.50% OK)\n",
      "  10. Arteritis/ endotheliitis/ vessel remodelling: 6 validations (100.00% OK)\n",
      "==================================================\n",
      "CRÉATION DES VISUALISATIONS PAR TYPE\n",
      "==================================================\n",
      "Visualisations créées:\n",
      "- taux_validation_par_type.png\n",
      "- comparaison_user4_user9_par_type.png\n",
      "- distribution_types_annotations.png\n",
      "\n",
      "============================================================\n",
      "ANALYSE PAR TYPE D'ANNOTATION TERMINÉE\n",
      "============================================================\n",
      "\n",
      "🎨 ÉTAPE 2: Visualisations avancées User4 vs User9\n",
      "EXÉCUTION DE TOUTES LES VISUALISATIONS AVANCÉES\n",
      "======================================================================\n",
      "============================================================\n",
      "CRÉATION DES VISUALISATIONS AVANCÉES POUR USER4 ET USER9\n",
      "============================================================\n",
      "1. Création de la heatmap de performance par type...\n",
      "2. Création du graphique radar...\n",
      "3. Création du graphique en barres empilées...\n",
      "4. Création du scatter plot volume vs performance...\n",
      "5. Création des violin plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benysar\\AppData\\Local\\Temp\\ipykernel_32792\\791297471.py:295: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.violinplot(data=violin_df, x='User', y='Performance', palette=['blue', 'green'])\n",
      "C:\\Users\\benysar\\AppData\\Local\\Temp\\ipykernel_32792\\791297471.py:295: UserWarning: \n",
      "The palette list has fewer values (2) than needed (9) and will cycle, which may produce an uninterpretable plot.\n",
      "  sns.violinplot(data=violin_df, x='User', y='Performance', palette=['blue', 'green'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"User4\" at position 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mlib.pyx:2391\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"User4\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m type_analysis_results \u001b[38;5;241m=\u001b[39m main_annotation_type_analysis()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎨 ÉTAPE 2: Visualisations avancées User4 vs User9\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m visualization_result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_all_advanced_visualizations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ ANALYSE TERMINÉE!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 673\u001b[0m, in \u001b[0;36mexecute_all_advanced_visualizations\u001b[1;34m()\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m    672\u001b[0m \u001b[38;5;66;03m# Créer les visualisations avancées\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m \u001b[43mcreate_advanced_user4_user9_visualizations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# Créer le dashboard comparatif\u001b[39;00m\n\u001b[0;32m    676\u001b[0m create_comparative_analysis_dashboard(df)\n",
      "Cell \u001b[1;32mIn[21], line 295\u001b[0m, in \u001b[0;36mcreate_advanced_user4_user9_visualizations\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    289\u001b[0m violin_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance\u001b[39m\u001b[38;5;124m'\u001b[39m: performance_data[::\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m: performance_data[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    292\u001b[0m })\n\u001b[0;32m    294\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m--> 295\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviolinplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviolin_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPerformance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m sns\u001b[38;5;241m.\u001b[39mstripplot(data\u001b[38;5;241m=\u001b[39mviolin_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    298\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution des performances par utilisateur\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn(toutes annotations)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benysar\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\seaborn\\categorical.py:1770\u001b[0m, in \u001b[0;36mviolinplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1767\u001b[0m kde_kws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(cut\u001b[38;5;241m=\u001b[39mcut, gridsize\u001b[38;5;241m=\u001b[39mgridsize, bw_method\u001b[38;5;241m=\u001b[39mbw_method, bw_adjust\u001b[38;5;241m=\u001b[39mbw_adjust)\n\u001b[0;32m   1768\u001b[0m inner_kws \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m inner_kws \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m inner_kws\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 1770\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_violins\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdodge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdensity_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdensity_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommon_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkde_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1787\u001b[0m p\u001b[38;5;241m.\u001b[39m_add_axis_labels(ax)\n\u001b[0;32m   1788\u001b[0m p\u001b[38;5;241m.\u001b[39m_adjust_cat_axis(ax, axis\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39morient)\n",
      "File \u001b[1;32mc:\\Users\\benysar\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\seaborn\\categorical.py:929\u001b[0m, in \u001b[0;36m_CategoricalPlotter.plot_violins\u001b[1;34m(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws)\u001b[0m\n\u001b[0;32m    926\u001b[0m violin_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    928\u001b[0m \u001b[38;5;66;03m# Iterate through all the data splits once to compute the KDEs\u001b[39;00m\n\u001b[1;32m--> 929\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_vars, sub_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_data(iter_vars,\n\u001b[0;32m    930\u001b[0m                                          from_comp_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    931\u001b[0m                                          allow_empty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    933\u001b[0m     sub_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sub_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    934\u001b[0m     stat_data \u001b[38;5;241m=\u001b[39m kde\u001b[38;5;241m.\u001b[39m_transform(sub_data, value_var, [])\n",
      "File \u001b[1;32mc:\\Users\\benysar\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\seaborn\\_base.py:902\u001b[0m, in \u001b[0;36mVectorPlotter.iter_data\u001b[1;34m(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)\u001b[0m\n\u001b[0;32m    899\u001b[0m grouping_vars \u001b[38;5;241m=\u001b[39m [var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables]\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_comp_data:\n\u001b[1;32m--> 902\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomp_data\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data\n",
      "File \u001b[1;32mc:\\Users\\benysar\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\seaborn\\_base.py:1000\u001b[0m, in \u001b[0;36mVectorPlotter.comp_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;66;03m# TODO this should happen in some centralized location\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;66;03m# it is similar to GH2419, but more complicated because\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;66;03m# supporting `order` in categorical plots is tricky\u001b[39;00m\n\u001b[0;32m    999\u001b[0m     orig \u001b[38;5;241m=\u001b[39m orig[orig\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels[var])]\n\u001b[1;32m-> 1000\u001b[0m comp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m   1001\u001b[0m transform \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform\n\u001b[0;32m   1002\u001b[0m parts\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mSeries(transform(comp), orig\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39morig\u001b[38;5;241m.\u001b[39mname))\n",
      "File \u001b[1;32mc:\\Users\\benysar\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\core\\tools\\numeric.py:232\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    230\u001b[0m coerce_numeric \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     values, new_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow_numpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mlib.pyx:2433\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"User4\" at position 5"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLULE FINALE - EXÉCUTION DE TOUTES LES NOUVELLES VISUALISATIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Importer les bibliothèques supplémentaires nécessaires\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "print(\"🚀 LANCEMENT DE L'ANALYSE COMPLÈTE AVEC VISUALISATIONS AVANCÉES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Exécuter d'abord l'analyse par type d'annotation\n",
    "print(\"\\n📊 ÉTAPE 1: Analyse par type d'annotation\")\n",
    "type_analysis_results = main_annotation_type_analysis()\n",
    "\n",
    "print(\"\\n🎨 ÉTAPE 2: Visualisations avancées User4 vs User9\")\n",
    "visualization_result = execute_all_advanced_visualizations()\n",
    "\n",
    "print(\"\\n✅ ANALYSE TERMINÉE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"📁 FICHIERS CRÉÉS:\")\n",
    "print(\"   📈 Analyses par type:\")\n",
    "print(\"      - taux_validation_par_type.png\")\n",
    "print(\"      - comparaison_user4_user9_par_type.png\")\n",
    "print(\"      - distribution_types_annotations.png\")\n",
    "print(\"\")\n",
    "print(\"   🎯 Visualisations avancées User4 vs User9:\")\n",
    "print(\"      - heatmap_user4_user9_performance.png\")\n",
    "print(\"      - radar_user4_user9_performance.png\")\n",
    "print(\"      - barres_empilees_user4_user9.png\")\n",
    "print(\"      - scatter_volume_performance_user4_user9.png\")\n",
    "print(\"      - violin_plot_user4_user9.png\")\n",
    "print(\"      - matrices_confusion_user4_user9.png\")\n",
    "print(\"      - evolution_performance_user4_user9.png\")\n",
    "print(\"      - specialites_user4_user9.png\")\n",
    "print(\"      - dashboard_comparatif_user4_user9.png\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Résumé des insights clés\n",
    "print(\"\\n🔍 INSIGHTS CLÉS DÉCOUVERTS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculer quelques statistiques rapides pour le résumé\n",
    "user4_data = df[df['USER'] == 'User4']\n",
    "user9_data = df[df['USER'] == 'User9']\n",
    "\n",
    "user4_total = len(user4_data)\n",
    "user4_ok_rate = (len(user4_data[user4_data['STATUS'] == 'OK']) / user4_total) * 100\n",
    "user9_total = len(user9_data)  \n",
    "user9_ok_rate = (len(user9_data[user9_data['STATUS'] == 'OK']) / user9_total) * 100\n",
    "\n",
    "print(f\"📌 User4: {user4_total} annotations, {user4_ok_rate:.1f}% de réussite\")\n",
    "print(f\"📌 User9: {user9_total} annotations, {user9_ok_rate:.1f}% de réussite\")\n",
    "print(f\"📌 Différence de performance: {abs(user4_ok_rate - user9_ok_rate):.1f}%\")\n",
    "\n",
    "# Types d'annotations les plus fréquents pour chaque utilisateur\n",
    "user4_top_type = user4_data['CL'].value_counts().index[0]\n",
    "user9_top_type = user9_data['CL'].value_counts().index[0]\n",
    "print(f\"📌 Type principal User4: {user4_top_type}\")\n",
    "print(f\"📌 Type principal User9: {user9_top_type}\")\n",
    "\n",
    "# Nombre de types uniques\n",
    "user4_unique_types = len(user4_data['CL'].unique())\n",
    "user9_unique_types = len(user9_data['CL'].unique())\n",
    "print(f\"📌 Diversité User4: {user4_unique_types} types différents\")\n",
    "print(f\"📌 Diversité User9: {user9_unique_types} types différents\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎉 ANALYSE COMPLÈTE TERMINÉE - CONSULTEZ LES GRAPHIQUES GÉNÉRÉS!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
