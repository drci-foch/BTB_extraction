{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/60lgrf9s6sqbf6lcr70gbl2c0000gn/T/ipykernel_91863/3862809403.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with pdf - obsolete \n",
    "Way too long !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def find_data_in_text(text):\n",
    "\n",
    "    # Multiline regex patterns for Nom, Prénom, Date de Naissance, and Sexe\n",
    "    nom_pattern = r\"(?i)NOM\\s*:\\s*([A-Z]+)\"\n",
    "    prenom_pattern = r\"Prénom\\s*:\\s*([A-Z\\s]+)\"\n",
    "\n",
    "    date_naissance_pattern = r\"Date de naissance\\s*:\\s*(\\d{2}/\\d{2}/\\d{4})\"\n",
    "    sexe_pattern = r\"Sexe\\s*:\\s*([MF])\"\n",
    "\n",
    "    # Using re.DOTALL to ensure dot matches across newlines\n",
    "    nom_match = re.search(nom_pattern, text, re.DOTALL)\n",
    "    prenom_match = re.search(prenom_pattern, text, re.DOTALL)\n",
    "    date_naissance_match = re.search(date_naissance_pattern, text, re.DOTALL)\n",
    "    sexe_match = re.search(sexe_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Extracting matched groups, handling None\n",
    "    nom = nom_match.group(1).strip() if nom_match else None\n",
    "    prenom = prenom_match.group(1).strip() if prenom_match else None\n",
    "    date_naissance = date_naissance_match.group(\n",
    "        1) if date_naissance_match else None\n",
    "    sexe = sexe_match.group(1) if sexe_match else None\n",
    "\n",
    "    return nom, prenom, date_naissance, sexe\n",
    "\n",
    "\n",
    "def process_pdf_files_in_directory(directory_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            # Extract IPP from the filename\n",
    "            ipp = filename[:9]\n",
    "\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            # Extract required information using the updated function\n",
    "            nom, prenom, date_naissance, sexe = find_data_in_text(text)\n",
    "\n",
    "            # Append the extracted data including IPP\n",
    "            data.append([filename, ipp, nom, prenom, date_naissance, sexe])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data, columns=[\"Filename\", \"IPP\", \"Nom\",\n",
    "                       \"Prénom\", \"Date de Naissance\", \"Sexe\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./data/data_extractMoustapha_2020:2021\"\n",
    "df = process_pdf_files_in_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>IPP</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Prénom</th>\n",
       "      <th>Date de Naissance</th>\n",
       "      <th>Sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300682227_13592AE5-5BE0-4E8D-9D80-8A293331E16B...</td>\n",
       "      <td>300682227</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>PHILIPPE\\nP</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300675753_24DC775E-103F-4F65-A0DC-7A495F0AF034...</td>\n",
       "      <td>300675753</td>\n",
       "      <td>KEBE</td>\n",
       "      <td>ABDOURAKHMANE \\n  \\n \\nKEBE \\n \\n \\nD</td>\n",
       "      <td>20/04/1968</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300694221_AFC7C13D-868B-451E-A237-23B84F0C3C86...</td>\n",
       "      <td>300694221</td>\n",
       "      <td>JEAN</td>\n",
       "      <td>JEAN FRANCIS\\nR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300554737_2DC418F3-6E5A-40CB-BAB7-2D243535195D...</td>\n",
       "      <td>300554737</td>\n",
       "      <td>CYRIL</td>\n",
       "      <td>CYRIL\\nR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300650079_D2D9735F-56F8-424F-AFD7-C26667993382...</td>\n",
       "      <td>300650079</td>\n",
       "      <td>DELOBEL</td>\n",
       "      <td>SOPHIE \\n  \\nN</td>\n",
       "      <td>04/08/1994</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>300375539_AC10B1F6-478E-4A33-9B6D-BA3A5D0C463B...</td>\n",
       "      <td>300375539</td>\n",
       "      <td>CHRISTOPHE</td>\n",
       "      <td>CHRISTOPHE\\nR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>300742430_D183372A-7A28-41D0-8551-F49667D72F1A...</td>\n",
       "      <td>300742430</td>\n",
       "      <td>JEAN</td>\n",
       "      <td>JEAN LOUIS\\nR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>300576539_9198748A-AF2C-4528-A742-5A3772FB51E3...</td>\n",
       "      <td>300576539</td>\n",
       "      <td>LE</td>\n",
       "      <td>CAMILLE \\n  \\nN</td>\n",
       "      <td>05/02/2000</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>300128818_F235BDCD-B101-4140-A6A2-1C9BEDF1D39A...</td>\n",
       "      <td>300128818</td>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>FLORENCE\\nR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>300688023_722AD36F-76B5-43B6-A3D2-98313A05474E...</td>\n",
       "      <td>300688023</td>\n",
       "      <td>LECOINTE</td>\n",
       "      <td>VALERIE \\n  \\nN</td>\n",
       "      <td>16/09/1990</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename        IPP  \\\n",
       "0     300682227_13592AE5-5BE0-4E8D-9D80-8A293331E16B...  300682227   \n",
       "1     300675753_24DC775E-103F-4F65-A0DC-7A495F0AF034...  300675753   \n",
       "2     300694221_AFC7C13D-868B-451E-A237-23B84F0C3C86...  300694221   \n",
       "3     300554737_2DC418F3-6E5A-40CB-BAB7-2D243535195D...  300554737   \n",
       "4     300650079_D2D9735F-56F8-424F-AFD7-C26667993382...  300650079   \n",
       "...                                                 ...        ...   \n",
       "1049  300375539_AC10B1F6-478E-4A33-9B6D-BA3A5D0C463B...  300375539   \n",
       "1050  300742430_D183372A-7A28-41D0-8551-F49667D72F1A...  300742430   \n",
       "1051  300576539_9198748A-AF2C-4528-A742-5A3772FB51E3...  300576539   \n",
       "1052  300128818_F235BDCD-B101-4140-A6A2-1C9BEDF1D39A...  300128818   \n",
       "1053  300688023_722AD36F-76B5-43B6-A3D2-98313A05474E...  300688023   \n",
       "\n",
       "             Nom                                 Prénom Date de Naissance  \\\n",
       "0       PHILIPPE                            PHILIPPE\\nP              None   \n",
       "1           KEBE  ABDOURAKHMANE \\n  \\n \\nKEBE \\n \\n \\nD        20/04/1968   \n",
       "2           JEAN                        JEAN FRANCIS\\nR              None   \n",
       "3          CYRIL                               CYRIL\\nR              None   \n",
       "4        DELOBEL                         SOPHIE \\n  \\nN        04/08/1994   \n",
       "...          ...                                    ...               ...   \n",
       "1049  CHRISTOPHE                          CHRISTOPHE\\nR              None   \n",
       "1050        JEAN                          JEAN LOUIS\\nR              None   \n",
       "1051          LE                        CAMILLE \\n  \\nN        05/02/2000   \n",
       "1052    FLORENCE                            FLORENCE\\nR              None   \n",
       "1053    LECOINTE                        VALERIE \\n  \\nN        16/09/1990   \n",
       "\n",
       "      Sexe  \n",
       "0        M  \n",
       "1        M  \n",
       "2     None  \n",
       "3     None  \n",
       "4        F  \n",
       "...    ...  \n",
       "1049  None  \n",
       "1050  None  \n",
       "1051     F  \n",
       "1052  None  \n",
       "1053     F  \n",
       "\n",
       "[1054 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going for txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prenom_before_docteur(text):\n",
    "    pattern = r\"Prénom\\s*:\\s*([A-Z\\s]+)\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        # Extract the captured group before \"Docteur\"\n",
    "        before_docteur = match.group(1)\n",
    "        first_name = before_docteur.split()[0] if before_docteur else None\n",
    "        return first_name\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_nom(text):\n",
    "    nom_pattern = r\"(?i)(^Nom\\s*:\\s*|Nom[\\s+]*usuel\\s*:\\s*|Nom\\s*:\\s*)([A-Z]+)\"\n",
    "    nom_match = re.search(nom_pattern, text, re.DOTALL)\n",
    "    return nom_match.group(2).strip() if nom_match else None\n",
    "\n",
    "\n",
    "def extract_ddn(text):\n",
    "    date_naissance_pattern = (\n",
    "        r\"(?i)(Date[\\s+]*de[\\s+]*naissance\\s*:\\s*)(\\d{2}/\\d{2}/\\d{4})\"\n",
    "    )\n",
    "    date_naissance_match = re.search(date_naissance_pattern, text, re.DOTALL)\n",
    "    return date_naissance_match.group(2).strip() if date_naissance_match else None\n",
    "\n",
    "\n",
    "def extract_sex(text):\n",
    "    sexe_pattern = r\"Sexe\\s*:\\s*([MF])\"\n",
    "    sexe_match = re.search(sexe_pattern, text, re.DOTALL)\n",
    "    return sexe_match.group(1) if sexe_match else None\n",
    "\n",
    "\n",
    "def extract_ddprelevement(text):\n",
    "    date_prelevement_pattern = (\n",
    "        r\"(?i)(Prélevé le \\s*:\\s*|Prélevé[\\s+]*le\\s*:\\s*)(\\d{2}/\\d{2}/\\d{4})\"\n",
    "    )\n",
    "    date_prelevement_match = re.search(date_prelevement_pattern, text, re.DOTALL)\n",
    "    return date_prelevement_match.group(2) if date_prelevement_match else None\n",
    "\n",
    "\n",
    "def extract_technique(text):\n",
    "    # Most found pattern\n",
    "    technique_pattern = r\"(2\\.|II\\.|I\\.|2/|2°/)[\\s+]*(Biopsies\\s+trans[ -]*bronchiques|Biopsies\\s+transbronchiques|Biospies\\s+transbronchiques|BTB)[\\s\\S+]*?Technique[^\\S\\r\\n]*:[^\\S\\r\\n]*([^;]+)\"\n",
    "    technique_match = re.search(technique_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    if not technique_match:\n",
    "        # Sometimes, there isn't the numbers, only \"Biopsie\" in text etc..\n",
    "        fallback_technique_pattern = r\"(Biopsies\\s+trans[ -]*bronchiques|Biopsies\\s+transbronchiques|Biospies\\s+transbronchiques|BTB)[\\s\\S+]*?Technique\\s*:\\s*([^;]+)\"\n",
    "        fallback_match = re.search(fallback_technique_pattern, text, re.DOTALL)\n",
    "        if fallback_match:\n",
    "            return fallback_match.group(2).strip()\n",
    "\n",
    "        else:\n",
    "            # No mention of biopsie or lavage, just the mention of techniques two times. The BTB technique is always second.\n",
    "            parts = re.split(r\"(?=Technique\\s*:)\", text, flags=re.IGNORECASE)\n",
    "            two_parts_fallback_technique_pattern = r\"Technique\\s*:\\s*([^;]+)\"\n",
    "            if len(parts) > 2:\n",
    "                two_parts_fallback_match = re.search(\n",
    "                    two_parts_fallback_technique_pattern, parts[-1], re.DOTALL\n",
    "                )\n",
    "                if two_parts_fallback_match:\n",
    "                    return two_parts_fallback_match.group(1).strip()\n",
    "\n",
    "            # Else, look at any mention of technique in the document\n",
    "            else:\n",
    "                last_fallback_technique_pattern = r\"Technique\\s*:\\s*([^;]+)\"\n",
    "                last_fallback_match = re.search(\n",
    "                    last_fallback_technique_pattern, text, re.DOTALL\n",
    "                )\n",
    "                if last_fallback_match:\n",
    "                    return last_fallback_match.group(1).strip()\n",
    "\n",
    "    return technique_match.group(3).strip() if technique_match else None\n",
    "\n",
    "\n",
    "def extract_niveaux_coupes(text):\n",
    "    \"\"\"\n",
    "    In this function we just reuse the extract_technique patterns to extract the group after the semi-colon\n",
    "    \"\"\"\n",
    "    # Most found pattern\n",
    "    technique_pattern = r\"(2\\.|II\\.|I\\.|2/|2°/)[\\s+]*(Biopsies\\s+trans[ -]*bronchiques|Biopsies\\s+transbronchiques|Biospies\\s+transbronchiques|BTB)[\\s\\S+]*?Technique\\s*:\\s*([^;]+);\\s*([^n]+)\"\n",
    "    technique_match = re.search(technique_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    if not technique_match:\n",
    "        # Sometimes, there isn't the numbers, only \"Biopsie\" in text etc..\n",
    "        fallback_technique_pattern = r\"(Biopsies\\s+trans[ -]*bronchiques|Biopsies\\s+transbronchiques|Biospies\\s+transbronchiques|BTB)[\\s\\S+]*?Technique\\s*:\\s*([^;]+);\\s*([^n]+)\"\n",
    "        fallback_match = re.search(fallback_technique_pattern, text, re.DOTALL)\n",
    "        if fallback_match:\n",
    "            return fallback_match.group(3).strip()\n",
    "\n",
    "        else:\n",
    "            # No mention of biopsie or lavage, just the mention of techniques two times. The BTB technique is always second.\n",
    "            parts = re.split(r\"(?=Technique\\s*:)\", text, flags=re.IGNORECASE)\n",
    "            two_parts_fallback_technique_pattern = r\"Technique\\s*:\\s*([^;]+);\\s*([^n]+)\"\n",
    "            if len(parts) > 2:\n",
    "                two_parts_fallback_match = re.search(\n",
    "                    two_parts_fallback_technique_pattern, parts[-1], re.DOTALL\n",
    "                )\n",
    "                if two_parts_fallback_match:\n",
    "                    return two_parts_fallback_match.group(2).strip()\n",
    "\n",
    "            # Else, look at any mention of technique in the document\n",
    "            else:\n",
    "                last_fallback_technique_pattern = r\"Technique\\s*:\\s*([^;]+);\\s*([^n]+)\"\n",
    "                last_fallback_match = re.search(\n",
    "                    last_fallback_technique_pattern, text, re.DOTALL\n",
    "                )\n",
    "                if last_fallback_match:\n",
    "                    return last_fallback_match.group(2).strip()\n",
    "\n",
    "    return technique_match.group(4).strip() if technique_match else None\n",
    "\n",
    "\n",
    "def extract_site(text):\n",
    "    site_pattern = r\"(Site[\\s\\xa0]*:)([\\S]*[^\\n]+)\"\n",
    "    site_match = re.search(site_pattern, text, re.DOTALL)\n",
    "    return site_match.group(2).strip() if site_match else None\n",
    "\n",
    "\n",
    "def extract_fragment_alveolaire(text):\n",
    "    frag_alveolaire_pattern = r\"(Nombre[\\s\\xa0]*de[\\s\\xa0]*fragments[\\s\\xa0]*alvéolaires[\\s\\xa0]*:)([\\S]*[^\\n]+)\"\n",
    "    frag_alveolaire_match = re.search(frag_alveolaire_pattern, text, re.DOTALL)\n",
    "    return frag_alveolaire_match.group(2).strip() if frag_alveolaire_match else None\n",
    "\n",
    "\n",
    "def extract_bronche_bronchiole(text):\n",
    "    bronche_bronchiole_pattern = r\"(Bronches\\/Bronchioles[\\s\\xa0]*:[\\s\\xa0]*|Bronches[\\s\\xa0]*\\/[\\s\\xa0]*Bronchioles[\\s\\xa0]*:[\\s\\xa0]*)([\\S]*[^\\n]+)\"\n",
    "    bronche_bronchiole_match = re.search(bronche_bronchiole_pattern, text, re.DOTALL)\n",
    "    return (\n",
    "        bronche_bronchiole_match.group(2).strip() if bronche_bronchiole_match else None\n",
    "    )\n",
    "\n",
    "def extract_infiltrat(text):\n",
    "    infiltrat_pattern = r\"(Infiltrat[\\s\\xa0]*mononucléé[\\s\\xa0]*péri(?:-|\\s*)?vasculaire[\\s\\xa0]*\\(A0[\\s\\xa0]*à[\\s\\xa0]*A4[\\s\\xa0]*\\/[\\s\\xa0]*AX\\)[\\s\\xa0]*:*:[\\s\\xa0]*|Infiltrat[\\s\\xa0]*mononucléé[\\s\\xa0]*péri(?:-|\\s*)?vasculaire[\\s\\xa0]*\\(A[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n]+)\"\n",
    "    infiltrat__match = re.search(infiltrat_pattern, text, re.DOTALL)\n",
    "    return infiltrat__match.group(2).strip() if infiltrat__match else None\n",
    "\n",
    "\n",
    "def extract_bronchiolite_lymph(text):\n",
    "    bronchlymph_pattern = r\"(Bronchiolite[\\s\\xa0]*lymphocytaire[\\s\\xa0]*\\(B0[\\s\\xa0]*\\/[\\s\\xa0]*1R[\\s\\xa0]*\\/[\\s\\xa0]*2R[\\s\\xa0]*\\/[\\s\\xa0]*BX\\)[\\s\\xa0]*:*:[\\s\\xa0]*|Bronchiolite[\\s\\xa0]*lymphocytaire[\\s\\xa0]*\\(B[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\w]*)\"\n",
    "    bronchlymph__match = re.search(bronchlymph_pattern, text, re.DOTALL)\n",
    "    return bronchlymph__match.group(2).strip() if bronchlymph__match else None\n",
    "\n",
    "\n",
    "def extract_infl_lymph(text):\n",
    "    infl_lymph_pattern = r\"(Inflammation[\\s\\xa0]*lymphocytaire[\\s\\xa0]*bronchique[\\s\\xa0]*\\([\\s\\xa0]*oui[\\s\\xa0]*\\/[\\s\\xa0]*non[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\w]*)\"\n",
    "    infl_lymph_match = re.search(infl_lymph_pattern, text, re.DOTALL)\n",
    "    return infl_lymph_match.group(2).strip() if infl_lymph_match else None\n",
    "\n",
    "def extract_bronch_obliter(text):\n",
    "    bronch_obliter_pattern = r\"Bronchiolite[\\s\\xa0]*(oblitérante|constrictive)[\\s\\xa0]*:*[\\s\\xa0]*([\\w\\s]*)\"\n",
    "    bronch_obliter_match = re.search(bronch_obliter_pattern, text, re.DOTALL)\n",
    "    return bronch_obliter_match.group(2).strip() if bronch_obliter_match else None\n",
    "\n",
    "def extract_fibroelastose(text):  \n",
    "    fibroelastose_pattern = r\"(Fibro(?:-|\\s*)?élastose[\\s\\xa0]*interstitielle [\\s\\xa0]*\\([\\s\\xa0]*0[\\s\\xa0]*ou[\\s\\xa0]*1[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\w]*)\"\n",
    "    fibroelastose_match = re.search(fibroelastose_pattern, text, re.DOTALL)\n",
    "    return fibroelastose_match.group(2).strip() if fibroelastose_match else None\n",
    "\n",
    "\n",
    "def extract_PNN_cloisons(text):\n",
    "    pnn_pattern = r\"(PNN[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*cloisons[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*|PNN[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*cloisons[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([^\\n]+)\"\n",
    "    pnn_match = re.search(pnn_pattern, text, re.DOTALL)\n",
    "    return pnn_match.group(2).strip() if pnn_match else None\n",
    "\n",
    "\n",
    "def extract_cellmono(text):\n",
    "    cellmono_pattern = r\"(Cellules[\\s\\xa0]*mononucléées[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*capillaires[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*|Cellules[\\s\\xa0]*mononuclées[\\s\\xa0]*\\(lymphocytes[\\s\\xa0]*ou[\\s\\xa0]*macrophages[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*cloisons[\\s\\xa0]*alvéolaires\\)[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n]+)\"\n",
    "    cellmono_match = re.search(cellmono_pattern, text, re.DOTALL)\n",
    "    return cellmono_match.group(2).strip() if cellmono_match else None\n",
    "\n",
    "def extract_dilatation(text):\n",
    "    dilatation_pattern = r\"(Dilatation[\\s\\xa0]*des[\\s\\xa0]*capillaires[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n]+)\"\n",
    "    dilatation_match = re.search(dilatation_pattern, text, re.DOTALL)\n",
    "    return dilatation_match.group(2).strip() if dilatation_match else None\n",
    "\n",
    "def extract_oedeme(text):\n",
    "    oedeme_pattern = r\"((Œdème|Oedème)[\\s\\xa0]*des[\\s\\xa0]*cloisons[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    oedeme_match = re.search(oedeme_pattern, text, re.DOTALL)\n",
    "    return oedeme_match.group(3).strip() if oedeme_match else None\n",
    "\n",
    "def extract_hyperplasie(text):\n",
    "    hyperplasie_pattern = r\"(Hyperplasie[\\s\\xa0]*pneumocytaire[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    hyperplasie_match = re.search(hyperplasie_pattern, text, re.DOTALL)\n",
    "    return hyperplasie_match.group(2).strip() if hyperplasie_match else None\n",
    "\n",
    "def extract_PNN_espace(text):\n",
    "    pnn_pattern = r\"(PNN[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*|PNN[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([^\\n]+)\"\n",
    "    pnn_match = re.search(pnn_pattern, text, re.DOTALL)\n",
    "    return pnn_match.group(2).strip() if pnn_match else None\n",
    "\n",
    "def extract_thrombifib(text):\n",
    "    tbf_pattern = r\"(Thrombi[\\s\\xa0]*fibrineux[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*capillaires[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    tbf_match = re.search(tbf_pattern, text, re.DOTALL)\n",
    "    return tbf_match.group(2).strip() if tbf_match else None\n",
    "\n",
    "def extract_debriscell(text):\n",
    "    debris_pattern = r\"(Débris[\\s\\xa0]*cellulaires[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*cloisons[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    debris_match = re.search(debris_pattern, text, re.DOTALL)\n",
    "    return debris_match.group(2).strip() if debris_match else None\n",
    "\n",
    "def extract_epaissfibreux(text):\n",
    "    epaiss_pattern = r\"(Epaississement[\\s\\xa0]*fibreux[\\s\\xa0]*des[\\s\\xa0]*cloisons[\\s\\xa0]*alvéolaires[\\s\\xa0]*(?:\\w*)?\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    epaiss_match = re.search(epaiss_pattern, text, re.DOTALL)\n",
    "    return epaiss_match.group(2).strip() if epaiss_match else None\n",
    "\n",
    "def extract_macrophages(text):\n",
    "    pattern = r\"(Macrophages[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_bourgeons(text):\n",
    "    pattern = r\"(Bourgeons[\\s\\xa0]*conjonctifs[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_bourgeons(text):\n",
    "    pattern = r\"(Bourgeons[\\s\\xa0]*conjonctifs[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_hematies(text):\n",
    "    pattern = r\"(Hématies[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_membranes(text):\n",
    "    pattern = r\"(Membranes[\\s\\xa0]*hyalines[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_fibrines(text):\n",
    "    pattern = r\"(Fibrine[\\s\\xa0]*dans[\\s\\xa0]*les[\\s\\xa0]*espaces[\\s\\xa0]*alvéolaires[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_inflspsbb(text):\n",
    "    pattern = r\"(Inflammation[\\s\\xa0]*sous(\\-|[\\s\\xa0])?pleurale,[\\s\\xa0]*septale,[\\s\\xa0]*bronchique[\\s\\xa0]*ou[\\s\\xa0]*bronchiolaire[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None \n",
    "\n",
    "def extract_inflspsbb(text):\n",
    "    pattern = r\"(Inflammation[\\s\\xa0]*sous(\\-|[\\s\\xa0])?pleurale,[\\s\\xa0]*septale,[\\s\\xa0]*bronchique[\\s\\xa0]*ou[\\s\\xa0]*bronchiolaire[\\s\\xa0]*\\(0[\\s\\xa0]*à[\\s\\xa0]*\\+\\+\\+[\\s\\xa0]*\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None\n",
    "\n",
    "def extract_BALT(text):\n",
    "    pattern = r\"(BALT[\\s\\xa0]*\\(oui\\/non\\)[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(2).strip() if match else None\n",
    "\n",
    "def extract_thrombus(text): \n",
    "    pattern = r\"(Thrombus[\\s\\xa0]*fibrino(\\-|[\\s\\xa0]|)?cruorique[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(4).strip() if match else None\n",
    "\n",
    "def extract_necrose(text): \n",
    "    pattern = r\"(Nécrose[\\s\\xa0]*ischémique[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None\n",
    "\n",
    "def extract_incluvirales(text): \n",
    "    pattern = r\"(Inclusions[\\s\\xa0]*virales[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None\n",
    "\n",
    "def extract_agentpatho(text):\n",
    "    pattern = r\"(Agent[\\s\\xa0]*pathogène[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None \n",
    "\n",
    "def extract_eosino(text):\n",
    "    pattern = r\"(Eosinophilie[\\s\\xa0]*(\\(interstitielle\\/alvéolaire\\)|)?[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(4).strip() if match else None     \n",
    "\n",
    "def extract_remodelage_vasculaire(text):\n",
    "    pattern = r\"(Remodelage[\\s\\xa0]*vasculaire[\\s\\xa0]*[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None   \n",
    "\n",
    "def extract_mat_etranger_inhalation(text):\n",
    "    pattern = r\"(Matériel[\\s\\xa0]*étranger[\\s\\xa0]*d’inhalation[\\s\\xa0]*(\\(oui\\/non\\)|)?[\\s\\xa0]*:*:[\\s\\xa0]*)([\\S]*[^\\n])\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(3).strip() if match else None  \n",
    "\n",
    "def extract_conclusion(text):\n",
    "    pattern = r\"(Conclusion[\\s\\xa0]*(:.*|)?)([\\s\\S]*)\"\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "    return match.group(3).strip() if match else None  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_files_in_directory(directory_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            ipp = filename[:9]\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            text = read_text_file(file_path)\n",
    "            nom = extract_nom(text)\n",
    "            prenom = extract_prenom_before_docteur(text)\n",
    "            ddn = extract_ddn(text)\n",
    "            sexe = extract_sex(text)\n",
    "            date_prelevement = extract_ddprelevement(text)\n",
    "            technique = extract_technique(text)\n",
    "            niveaux = extract_niveaux_coupes(text)\n",
    "            site = extract_site(text)\n",
    "            frag_alv = extract_fragment_alveolaire(text)\n",
    "            bronche_bronchiole = extract_bronche_bronchiole(text)\n",
    "            infiltrat = extract_infiltrat(text)\n",
    "            bronch_lymph = extract_bronchiolite_lymph(text)\n",
    "            infl_lymph = extract_infl_lymph(text)\n",
    "            bronch_obliter = extract_bronch_obliter(text)\n",
    "            fibro_elastose = extract_fibroelastose(text)\n",
    "            pnn_cloisons = extract_PNN_cloisons(text)\n",
    "            cellmono = extract_cellmono(text)\n",
    "            dilatation = extract_dilatation(text)\n",
    "            oedeme = extract_oedeme(text)\n",
    "            hyperplasie = extract_hyperplasie(text)\n",
    "            pnn_espaces = extract_PNN_espace(text)\n",
    "            tbf = extract_thrombifib(text)\n",
    "            debris = extract_debriscell(text)\n",
    "            epaiss_fibreux = extract_epaissfibreux(text)\n",
    "            macrophages = extract_macrophages(text)\n",
    "            bourgeons = extract_bourgeons(text)\n",
    "            hematies = extract_hematies(text)\n",
    "            membranes = extract_membranes(text)\n",
    "            fibrines = extract_fibrines(text)\n",
    "            inflspbb = extract_inflspsbb(text)\n",
    "            balt = extract_BALT(text)\n",
    "            thrombus = extract_thrombus(text)\n",
    "            necrose = extract_necrose(text)\n",
    "            inclus_virale = extract_incluvirales(text)\n",
    "            agent_patho = extract_agentpatho(text)\n",
    "            eosino = extract_eosino(text)\n",
    "            remodelage_vasculaire = extract_remodelage_vasculaire(text)\n",
    "            mat_etranger_inhalation = extract_mat_etranger_inhalation(text)\n",
    "            conclusion = extract_conclusion(text)\n",
    "            data.append(\n",
    "                [\n",
    "                    filename,\n",
    "                    ipp,\n",
    "                    nom,\n",
    "                    prenom,\n",
    "                    ddn,\n",
    "                    sexe,\n",
    "                    date_prelevement,\n",
    "                    technique,\n",
    "                    niveaux,\n",
    "                    site,\n",
    "                    frag_alv,\n",
    "                    bronche_bronchiole,\n",
    "                    infiltrat,\n",
    "                    bronch_lymph,\n",
    "                    infl_lymph,\n",
    "                    bronch_obliter,\n",
    "                    fibro_elastose,\n",
    "                    pnn_cloisons,\n",
    "                    cellmono,\n",
    "                    dilatation,\n",
    "                    oedeme,\n",
    "                    tbf,\n",
    "                    debris,\n",
    "                    epaiss_fibreux,\n",
    "                    hyperplasie,\n",
    "                    pnn_espaces,\n",
    "                    macrophages,\n",
    "                    bourgeons,\n",
    "                    hematies,\n",
    "                    membranes,\n",
    "                    fibrines,\n",
    "                    inflspbb,\n",
    "                    balt,\n",
    "                    thrombus,\n",
    "                    necrose,\n",
    "                    inclus_virale,\n",
    "                    agent_patho,\n",
    "                    eosino,\n",
    "                    remodelage_vasculaire,\n",
    "                    mat_etranger_inhalation,\n",
    "                    conclusion\n",
    "                    \n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"Filename\",\n",
    "            \"IPP\",\n",
    "            \"Nom\",\n",
    "            \"Prénom\",\n",
    "            \"Date de naissance\",\n",
    "            \"Sexe\",\n",
    "            \"Date de Prélèvement\",\n",
    "            \"Technique\",\n",
    "            \"Niveaux de coupes\",\n",
    "            \"Site\",\n",
    "            \"Nombre de fragment alvéolaire\",\n",
    "            \"Bronches/Bronchioles\",\n",
    "            \"Infiltrat\",\n",
    "            \"Bronchiolite Lymphocytaire\",\n",
    "            \"Inflammation Lymphocytaire\",\n",
    "            \"Bronchiolite oblitérante\",\n",
    "            \"Fibro-élastose interstitielle\",\n",
    "            \"PNN dans les cloisons alvéolaires\",\n",
    "            \"Cellules mononucléées\",\n",
    "            \"Dilatation des capillaires alvéolaires\",\n",
    "            \"Œdème des cloisons alvéolaires\",\n",
    "            \"Thrombi fibrineux dans les capillaires alvéolaires\",\n",
    "            \"Débris cellulaires dans les cloisons alvéolaires\",\n",
    "            \"Epaississement fibreux des cloisons alvéolaires\",\n",
    "            \"Hyperplasie pneumocytaire\",\n",
    "            \"PNN dans les espaces alvéolaires\",\n",
    "            \"Macrophages dans les espaces alvéolaires\",\n",
    "            \"Bourgeons conjonctifs dans les espaces alvéolaires\",\n",
    "            \"Hématies dans les espaces alvéolaires\",\n",
    "            \"Membranes hyalines\",\n",
    "            \"Fibrine dans les espaces alvéolaires\",\n",
    "            \"Inflammation sous-pleurale, septale, bronchique ou bronchiolaire\",\n",
    "            \"BALT\",\n",
    "            \"Thrombus fibrino-cruorique\",\n",
    "            \"Nécrose ischémique\",\n",
    "            \"Inclusions virales\",\n",
    "            \"Agent pathogène\",\n",
    "            \"Eosinophilie (interstitielle/alvéolaire)\",\n",
    "            \"Remodelage vasculaire\",\n",
    "            \"Matériel étranger d’inhalation\",\n",
    "            \"Conclusion\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "# Replace 'path_to_your_directory_with_txts' with your directory's path\n",
    "directory_path = \"./data/data_extractMoustapha_2020:2021\"\n",
    "df = process_text_files_in_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>IPP</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Prénom</th>\n",
       "      <th>Date de naissance</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>Date de Prélèvement</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Niveaux de coupes</th>\n",
       "      <th>Site</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflammation sous-pleurale, septale, bronchique ou bronchiolaire</th>\n",
       "      <th>BALT</th>\n",
       "      <th>Thrombus fibrino-cruorique</th>\n",
       "      <th>Nécrose ischémique</th>\n",
       "      <th>Inclusions virales</th>\n",
       "      <th>Agent pathogène</th>\n",
       "      <th>Eosinophilie (interstitielle/alvéolaire)</th>\n",
       "      <th>Remodelage vasculaire</th>\n",
       "      <th>Matériel étranger d’inhalation</th>\n",
       "      <th>Conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300531886_69018907-395A-434F-9EAB-B2A9642866EA...</td>\n",
       "      <td>300531886</td>\n",
       "      <td>BOUTARD</td>\n",
       "      <td>BRUNO</td>\n",
       "      <td>04/05/1961</td>\n",
       "      <td>M</td>\n",
       "      <td>31/03/2021</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>non précisé</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>1/  Lavage    broncho    alvéolaire   :       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300701581_C8216C08-75B0-4744-AB27-3AE0A89B94C4...</td>\n",
       "      <td>300701581</td>\n",
       "      <td>CAZEAU</td>\n",
       "      <td>Jean</td>\n",
       "      <td>28/05/1958</td>\n",
       "      <td>M</td>\n",
       "      <td>24/10/2021</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>LID + LM</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300676564_7278152A-DC79-4712-9856-19494341CAB2...</td>\n",
       "      <td>300676564</td>\n",
       "      <td>ROLI</td>\n",
       "      <td>JULIEN</td>\n",
       "      <td>08/06/1981</td>\n",
       "      <td>M</td>\n",
       "      <td>28/05/2020</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lavage bronchiolo-alvéolaire de cellularité él...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300720938_6C09898C-B815-432C-96F4-9759FBAA74CB...</td>\n",
       "      <td>300720938</td>\n",
       "      <td>GUERN</td>\n",
       "      <td>LAURENCE</td>\n",
       "      <td>01/12/1970</td>\n",
       "      <td>F</td>\n",
       "      <td>13/09/2021</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>LIG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300554737_3D17E344-E143-4B89-BCF4-30D55CBB1FF4...</td>\n",
       "      <td>300554737</td>\n",
       "      <td>CHARNAY</td>\n",
       "      <td>CYRIL</td>\n",
       "      <td>06/06/1993</td>\n",
       "      <td>M</td>\n",
       "      <td>26/03/2020</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lavage      bronchiolo-alvéolaire         de  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>300553661_4C54ECD5-BFBD-43AA-8295-39F30E33A3C8...</td>\n",
       "      <td>300553661</td>\n",
       "      <td>NUSSBAUMER</td>\n",
       "      <td>MYRTILLE</td>\n",
       "      <td>23/04/2001</td>\n",
       "      <td>F</td>\n",
       "      <td>24/11/2021</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>LID + LM</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>no</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>300670280_5A7A38FB-F732-4E34-898E-72D44F214041...</td>\n",
       "      <td>300670280</td>\n",
       "      <td>ARMAND</td>\n",
       "      <td>DANIEL</td>\n",
       "      <td>15/05/1956</td>\n",
       "      <td>M</td>\n",
       "      <td>03/03/2020</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>LID</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lavage bronchiolo-alvéolaire de cellularité un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>300732450_DEBAB80B-F589-41AE-AA08-5F2E0D83659F...</td>\n",
       "      <td>300732450</td>\n",
       "      <td>BOYER</td>\n",
       "      <td>FABIOLA</td>\n",
       "      <td>26/02/1988</td>\n",
       "      <td>F</td>\n",
       "      <td>06/07/2021</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>LID</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>Lavage     bronchiolo-alvéolaire       de  cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>300409902_C9E9AFE4-1FBE-4C3E-9E2E-31B1706285AA...</td>\n",
       "      <td>300409902</td>\n",
       "      <td>BOGE</td>\n",
       "      <td>GILLES</td>\n",
       "      <td>14/10/1956</td>\n",
       "      <td>M</td>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>LM/LID</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I – Biopsies    transbronchiques       (LID/LM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>300732321_E614E8F0-6228-4C57-9746-2103525BA49B...</td>\n",
       "      <td>300732321</td>\n",
       "      <td>DEGROIS</td>\n",
       "      <td>NADEGE</td>\n",
       "      <td>15/05/1981</td>\n",
       "      <td>F</td>\n",
       "      <td>04/03/2021</td>\n",
       "      <td>HES</td>\n",
       "      <td>16</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filename        IPP  \\\n",
       "0     300531886_69018907-395A-434F-9EAB-B2A9642866EA...  300531886   \n",
       "1     300701581_C8216C08-75B0-4744-AB27-3AE0A89B94C4...  300701581   \n",
       "2     300676564_7278152A-DC79-4712-9856-19494341CAB2...  300676564   \n",
       "3     300720938_6C09898C-B815-432C-96F4-9759FBAA74CB...  300720938   \n",
       "4     300554737_3D17E344-E143-4B89-BCF4-30D55CBB1FF4...  300554737   \n",
       "...                                                 ...        ...   \n",
       "1049  300553661_4C54ECD5-BFBD-43AA-8295-39F30E33A3C8...  300553661   \n",
       "1050  300670280_5A7A38FB-F732-4E34-898E-72D44F214041...  300670280   \n",
       "1051  300732450_DEBAB80B-F589-41AE-AA08-5F2E0D83659F...  300732450   \n",
       "1052  300409902_C9E9AFE4-1FBE-4C3E-9E2E-31B1706285AA...  300409902   \n",
       "1053  300732321_E614E8F0-6228-4C57-9746-2103525BA49B...  300732321   \n",
       "\n",
       "             Nom    Prénom Date de naissance Sexe Date de Prélèvement  \\\n",
       "0        BOUTARD     BRUNO        04/05/1961    M          31/03/2021   \n",
       "1         CAZEAU      Jean        28/05/1958    M          24/10/2021   \n",
       "2           ROLI    JULIEN        08/06/1981    M          28/05/2020   \n",
       "3          GUERN  LAURENCE        01/12/1970    F          13/09/2021   \n",
       "4        CHARNAY     CYRIL        06/06/1993    M          26/03/2020   \n",
       "...          ...       ...               ...  ...                 ...   \n",
       "1049  NUSSBAUMER  MYRTILLE        23/04/2001    F          24/11/2021   \n",
       "1050      ARMAND    DANIEL        15/05/1956    M          03/03/2020   \n",
       "1051       BOYER   FABIOLA        26/02/1988    F          06/07/2021   \n",
       "1052        BOGE    GILLES        14/10/1956    M          04/08/2020   \n",
       "1053     DEGROIS    NADEGE        15/05/1981    F          04/03/2021   \n",
       "\n",
       "     Technique Niveaux de coupes         Site  ...  \\\n",
       "0          HES                16  non précisé  ...   \n",
       "1          HES                16     LID + LM  ...   \n",
       "2          HES                16               ...   \n",
       "3          HES                16          LIG  ...   \n",
       "4          HES                16               ...   \n",
       "...        ...               ...          ...  ...   \n",
       "1049       HES                16     LID + LM  ...   \n",
       "1050       HES                16          LID  ...   \n",
       "1051       HES                16          LID  ...   \n",
       "1052       HES                16       LM/LID  ...   \n",
       "1053       HES                16            -  ...   \n",
       "\n",
       "     Inflammation sous-pleurale, septale, bronchique ou bronchiolaire  BALT  \\\n",
       "0                                                     0                 non   \n",
       "1                                                     0                 non   \n",
       "2                                                  None                None   \n",
       "3                                                     0                 non   \n",
       "4                                                  None                None   \n",
       "...                                                 ...                 ...   \n",
       "1049                                                  0                 non   \n",
       "1050                                               None                None   \n",
       "1051                                                  0                 non   \n",
       "1052                                               None                None   \n",
       "1053                                                  0                 non   \n",
       "\n",
       "     Thrombus fibrino-cruorique Nécrose ischémique Inclusions virales  \\\n",
       "0                           non                non                non   \n",
       "1                           non                non                non   \n",
       "2                             0                  0                  0   \n",
       "3                           non                non                non   \n",
       "4                             0                  0                  0   \n",
       "...                         ...                ...                ...   \n",
       "1049                        non                non                non   \n",
       "1050                          0                  0                  0   \n",
       "1051                        non                non                non   \n",
       "1052                          0                  0                  0   \n",
       "1053                        non                non                non   \n",
       "\n",
       "     Agent pathogène Eosinophilie (interstitielle/alvéolaire)  \\\n",
       "0                non                                      non   \n",
       "1                non                                      non   \n",
       "2               None                                     None   \n",
       "3                non                                      non   \n",
       "4               None                                     None   \n",
       "...              ...                                      ...   \n",
       "1049              no                                      non   \n",
       "1050            None                                     None   \n",
       "1051             non                                      non   \n",
       "1052            None                                     None   \n",
       "1053             non                                      non   \n",
       "\n",
       "     Remodelage vasculaire Matériel étranger d’inhalation  \\\n",
       "0                      non                            non   \n",
       "1                      non                            non   \n",
       "2                     None                           None   \n",
       "3                      non                            non   \n",
       "4                     None                           None   \n",
       "...                    ...                            ...   \n",
       "1049                   non                            non   \n",
       "1050                  None                           None   \n",
       "1051                   non                            non   \n",
       "1052                  None                           None   \n",
       "1053                   non                            non   \n",
       "\n",
       "                                             Conclusion  \n",
       "0     1/  Lavage    broncho    alvéolaire   :       ...  \n",
       "1                                                        \n",
       "2     Lavage bronchiolo-alvéolaire de cellularité él...  \n",
       "3                                                        \n",
       "4     Lavage      bronchiolo-alvéolaire         de  ...  \n",
       "...                                                 ...  \n",
       "1049                                                     \n",
       "1050  Lavage bronchiolo-alvéolaire de cellularité un...  \n",
       "1051  Lavage     bronchiolo-alvéolaire       de  cel...  \n",
       "1052  I – Biopsies    transbronchiques       (LID/LM...  \n",
       "1053                                                     \n",
       "\n",
       "[1054 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames are saved in 'data_summary.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "df['Date de Prélèvement'] = pd.to_datetime(df['Date de Prélèvement'])\n",
    "\n",
    "unique_values_dict = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in ['IPP','Filename','Nom','Prénom','Date de naissance','Date de Prélèvement','Conclusion']:\n",
    "        continue\n",
    "    unique_values = df[column].dropna().unique().tolist()\n",
    "    unique_values_dict[column] = unique_values\n",
    "max_len = max(len(v) for v in unique_values_dict.values()) \n",
    "for column in unique_values_dict.keys():\n",
    "    current_len = len(unique_values_dict[column])\n",
    "    if current_len < max_len:\n",
    "        unique_values_dict[column].extend([None] * (max_len - current_len))\n",
    "\n",
    "unique_values_df = pd.DataFrame(unique_values_dict)\n",
    "\n",
    "unique_values_counts = df.nunique()\n",
    "na_counts = df.isna().sum()\n",
    "df['Year'] = df['Date de Prélèvement'].dt.year\n",
    "na_counts_by_year = df.groupby('Year').apply(lambda x: x.isna().sum()).drop('Year', axis=1)\n",
    "\n",
    "with pd.ExcelWriter('data_summary.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    unique_values_counts.to_frame(name='Unique Values Count').to_excel(writer, sheet_name='Unique Values Counts')\n",
    "    na_counts.to_frame(name='NA Counts').to_excel(writer, sheet_name='NA Counts')\n",
    "    na_counts_by_year.to_excel(writer, sheet_name='NA Counts by Year')\n",
    "    unique_values_df.to_excel(writer, sheet_name='Unique Values')\n",
    "\n",
    "print(\"DataFrames are saved in 'data_summary.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
